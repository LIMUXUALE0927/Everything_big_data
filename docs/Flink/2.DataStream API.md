# DataStream API

## DataStream

Flink 提供的四种 API：

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410050215317.png)

DataStream 是 Flink 中不可变的数据集合。其中的数据既可以是有界的，也可以是无界的，不过处理它们所用的 API 是一样的。

DataStream 在使用方式上和常规的 Java 集合有些相似，但在一些关键地方又大不相同：

- 它是不可变的，即一旦创建好，便无法往里添加或者删除元素了
- 不能直接查看其中的元素，只能通过 DataStream API 提供的操作（也就是所谓的 “转换” 操作）来对其进行处理

---

## Example Program

```java
public class WindowWordCount {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        DataStream<Tuple2<String, Integer>> dataStream = env
                .socketTextStream("localhost", 9999)
                .flatMap(new Splitter())
                .keyBy(value -> value.f0)
                .window(TumblingProcessingTimeWindows.of(Duration.ofSeconds(5)))
                .sum(1);

        dataStream.print();
        env.execute("Window WordCount");
    }

    public static class Splitter implements FlatMapFunction<String, Tuple2<String, Integer>> {
        @Override
        public void flatMap(String sentence, Collector<Tuple2<String, Integer>> out) {
            for (String word : sentence.split(" ")) {
                out.collect(Tuple2.of(word, 1));
            }
        }
    }
}
```

---

## Source

Sources are where your program reads its input from. You can attach a source to your program by using `StreamExecutionEnvironment.addSource(sourceFunction)`. Flink comes with a number of pre-implemented source functions, but you can always write your own custom sources by implementing the **SourceFunction** for non-parallel sources, or by implementing the **ParallelSourceFunction** interface or extending the **RichParallelSourceFunction** for parallel sources.

如果对 Data Source 的原理部分感兴趣，可以参考：[Data Sources](https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/sources/)

### 集合数据源

```java
public class SourceTest {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        DataStreamSource<Event> stream = env.fromElements(
                new Event("Alice", "www.baidu.com", 123456789L),
                new Event("Bob", "www.google.com", 123456789L),
                new Event("Alice", "www.sina.com", 123456789L)
        );
//        ArrayList<Event> events = new ArrayList<>();
//        events.add(new Event("Alice", "www.baidu.com", 123456789L));
//        events.add(new Event("Bob", "www.google.com", 123456789L));
//        events.add(new Event("Alice", "www.sina.com", 123456789L));
//        DataStreamSource<Event> stream2 = env.fromCollection(events);
        stream.print();
        env.execute();
    }
}
```

### 文件数据源

```java
public class FileTest {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        DataStreamSource<String> stream = env.readTextFile("data/input.txt");
        stream.print();
        env.execute();
    }
}
```

---

### Socket 数据源

```java
public class SocketTest {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        DataStreamSource<String> stream = env.socketTextStream("localhost", 9999);
        stream.print();
        env.execute();
    }
}
```

---

### Kafka 数据源

`FlinkKafkaConsumer` 在 Flink 1.17 中删除，请改用 `KafkaSource`。

```java
KafkaSource<String> source = KafkaSource.<String>builder()
    .setBootstrapServers(brokers)
    .setTopics("input-topic")
    .setGroupId("my-group")
    .setStartingOffsets(OffsetsInitializer.earliest())
    .setValueOnlyDeserializer(new SimpleStringSchema())
    .build();

env.fromSource(source, WatermarkStrategy.noWatermarks(), "Kafka Source");
```

---

### 自定义数据源

创建一个自定义的数据源，需要实现 SourceFunction 接口并且重写两个关键方法：`run()` 和 `cancel()`。

- `run()`方法：使用运行时上下文对象（SourceContext）向下游发送数据
- `cancel()`方法：通过标识位控制退出循环，来达到中断数据源的效果

如果需要自定义并行的数据源（并行度>1），需要实现 ParallelSourceFunction 接口，并重写 `run()` 和 `cancel()`。

```java
public class CustomSource implements SourceFunction<Event> {
    private Boolean running = true;

    @Override
    public void run(SourceContext<Event> sourceContext) throws Exception {
        while (running) {
            sourceContext.collect(new Event("user", "url", System.currentTimeMillis()));
            Thread.sleep(1000);
        }
    }

    @Override
    public void cancel() {
        running = false;
    }
}
```

---

## Transformation

各类 Transformation 操作 [API](https://nightlies.apache.org/flink/flink-docs-release-1.20/zh/docs/dev/datastream/operators/overview/)

### Map

将 DataStream 中的每一个元素转换为另外一个元素。

```java
env.fromElements(1, 2, 3, 4)
    .map(x -> x * 2)
    .print();
```

### Filter

计算每个数据元的布尔函数，并保存函数返回 true 的数据元。

```java
env.fromElements(1, 2, 3, 4)
    .filter(x -> x % 2 == 0)
    .print();
```

### FlatMap

FlatMap 操作用于数据展开映射，是 Filter + Map 的组合以及扩展。FlatMap 可以实现加工输入数据并改变数据的数据类型，然后不输出数据或输出多条数据。

```java
env.fromElements("hello world", "world", "hello")
    .flatMap((String line, Collector<String> out) -> {
        for (String word : line.split(" ")) {
            if (word.equals("world")) {
                out.collect(word);
            }
        }
    })
    .returns(Types.STRING)
    .print();
```

### KeyBy

KeyBy 操作可以将一条输入 DataStream 按照 key 转换为分组的数据流 **KeyedStream**。DataStream API 提供了 `KeyedStream<T, K> keyBy(KeySelector<T, K> key)` 方法来完成数据的分组操作，其中 T 为输入的数据类型，K 为数据分组键的类型。

```java
stream.keyBy(x -> x.getSomeKey());
stream.keyBy(x -> x.f0);
```

### Max/Min/Sum

对分组的数据进行聚合。

```java
stream.keyBy(x -> x.f0).sum("f0");
```

### Reduce

对于 min/max/sum 无法处理的聚合计算逻辑，可以通过 reduce 操作来自定义数据聚合计算的逻辑。

使用时需要实现 `reduce(T acc, T in)` 方法，acc 表示该分组的历史聚合结果，in 表示该分组中新的输入数据。

```java
public interface ReduceFunction<T> extends Function, Serializable {
    T reduce(T acc, T in) throws Exception;
}
```

---

## Sink

### 控制台

```java
stream.print();
```

### Kafka

```java
DataStream<String> stream = ...;

KafkaSink<String> sink = KafkaSink.<String>builder()
        .setBootstrapServers(brokers)
        .setRecordSerializer(KafkaRecordSerializationSchema.builder()
            .setTopic("topic-name")
            .setValueSerializationSchema(new SimpleStringSchema())
            .build()
        )
        .setDeliveryGuarantee(DeliveryGuarantee.AT_LEAST_ONCE)
        .build();

stream.sinkTo(sink);
```

### 自定义 Sink

---

## 算子间数据传输的 8 种策略

### Forward

Forward 指上下游算子在传输时一对一的模式，是 Flink 的默认传输策略，前提是上下游算子并行度相同。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502102000808.png)

---

### Rebalance

在 Rebalance 传输策略下，上游算子会按照轮询模式传输数据给下游算子。轮询算法是 Round-Robin 负载均衡算法。RebalancePartitioner 会先随机选一个下游分区，之后轮询遍历下游所有分区进行数据传输。

在用户没有指定其他数据传输策略（如 Shuffle、Rescale 等）并且不满足 Forward 传输策略的条件下，Flink 默认使用 Rebalance 传输策略。

**应用场景**：当一个算子的不同 SubTask 之间要处理的数据量差异很大，导致出现数据倾斜时，可以使用 Rebalance 传输策略来缓解数据倾斜的问题。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502102004573.png)

上下游算子并行度相同时使用 Rebalance 缓解数据倾斜：

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502102008181.png)

上下游算子并行度不同时的 Rebalance 传输策略：

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502102008495.png)

!!! note "总结"

    Forward 和 Rebalance 是 Flink 引擎根据算子并行度等因素默认为上下游算子指定的数据传输策略。而针对接下来的其余 6 种数据传输策略，只要用户不通过代码主动设置，算子之间是不会使用这 6 种数据传输策略的。

---

### Shuffle

Shuffle 传输策略是另一个版本的 Rebalance 传输策略，Shuffle 和 Rebalance 传输策略都可以做到数据的均匀下发。当算子之间使用 Shuffle 传输策略，上游算子的 SubTask 往下游算子的 SubTask 传输数据时，会随机选择一个下游算子的 SubTask 进行下发。

我们可以使用 `DataStream.shuffle()` 将上下游算子之间的数据传输策略设置为 Shuffle。

---

### KeyGroup

当我们使用了 KeyBy 操作后，上下游算子之间的数据传输策略就是 KeyGroup。

对于 KeyGroup 传输策略来说，上游算子的每一个 SubTask 对于每一条数据，会通过 `DataStream.keyBy()` 方法的入参 KeySelector 来获取 key，然后根据这个 key 经过哈希算法计算要将该条数据下发到下游算子的哪一个 SubTask 中，相同 key 的数据会被下发到同一个 SubTask 中进行处理。此外，**KeyGroup 也称作哈希传输策略**，在 Flink Web UI 中 Flink 作业的逻辑数据流图会展示为哈希。

---

### Rescale

和 Rebalance 不同的地方在于，Rescale 并不是完全将数据轮询下发到下游算子的所有 SubTask 中，而是轮询下发到下游算子的一部分 SubTask 中。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502102041350.png)

Rescale 传输策略和 Rebalance 传输策略是类似的，主要差异有以下 3 点：

- Rescale 比 Rebalance 占用的网络传输资源更小，Rebalance 传输策略中，上游的每一个 SubTask 都要连接下游所有的 SubTask，而 Rescale 只需要连接下游算子的部分 SubTask。
- Rescale 比 Rebalance 对于数据乱序的影响更小，在 Rebalance 传输策略中，由于数据会轮询下发到下游算子所有的 SubTask 中，所以在这个过程中会加剧数据乱序，而 Rescale 只是下发到下游算子的部分 SubTask 中，因此数据乱序的程度相比 Rebalance 更小。数据乱序问题会对时间窗口算子的数据计算过程产生影响。
- Rebalance 相比于 Rescale 来说，下发到下游算子 SubTask 中的数据量更加均匀。

---

### Broadcast

Broadcast 会将上游每一条数据都下发给下游算子的所有 SubTask。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502102042712.png)

Broadcast 主要的使用场景是大数据流关联操作（Join）小数据流场景。举例来说，A 流为数据流量大的一条数据流，B 流为数据流量小的一条数据流，A 流和 B 流中的数据都包含 unique_id 字段，现在的需求是 A 流和 B 流通过 unique_id 做数据关联。当面临这种需求时，我们的第一反应往往是对两条数据流进行 KeyBy 操作，将相同 unique_id 的数据发送到相同的 SubTask 中进行关联处理。这种方案的缺点在于如果出现热点 unique_id，就会导致数据倾斜。而这时就可以使用 Broadcast 传输策略来解决这个问题，我们可以对 B 流中的数据进行广播，将 B 流的数据广播到 A 流的所有 SubTask 中进行数据关联，以此来避免数据倾斜。

---

### Global

在 Global 的传输策略下，上游算子会将所有数据下发到下游算子下标为 0 的 SubTask 中，即使下游算子的并行度大于 1。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502102044978.png)

---

### Custom Partition

自定义传输策略。使用 `DataStream.partitionCustom(Partitioner p, KeySelector k)` 方法来自定义数据传输策略，SubTask 在执行自定义传输策略时分为 2 个步骤：

1. 使用 KeySelector 获取当前数据的 key
2. 执行 Partitioner

---

## 执行模式（流/批）

DataStream API 有一种”经典“的执行行为，我们称之为流（STREAMING）执行模式。这种模式适用于需要连续增量处理，而且常驻线上的无边界作业。

此外，还有一种批式执行模式，我们称之为批（BATCH）执行模式。这种执行作业的方式类似于 MapReduce 等批处理框架，适用于已知输入、不会连续运行的的有边界作业。

Apache Flink 对流处理和批处理采取统一的处理方式，这意味着无论配置何种执行模式，在有界输入上执行的 DataStream 应用都会产生相同的**最终结果**。重要的是要注意最终在这里是什么意思：一个在流模式执行的作业可能会产生**增量更新**（想想数据库中的 **upsert** 操作），而批作业只在最后产生一个最终结果。尽管计算方法不同，只要呈现方式得当，最终结果会是相同的。

**通过启用批执行模式，Flink 可以对有边界作业进行额外的优化**。例如，可以使用不同的关联（join）/ 聚合（aggregation）策略、不同 shuffle 实现来提高任务调度和故障恢复的效率。

执行模式可以通过 `execution.runtime-mode` 设置来配置。有三种可选的值：

- STREAMING: 经典 DataStream 执行模式（默认）
- BATCH: 在 DataStream API 上进行批量式执行
- AUTOMATIC: 让系统根据数据源的边界性来决定

这可以通过 `bin/flink run ...` 的命令行参数进行配置，或者在创建/配置 `StreamExecutionEnvironment` 时写进程序。

下面是如何通过命令行配置执行模式：

```shell
$ bin/flink run -Dexecution.runtime-mode=BATCH <jarFile>
```

这个例子展示了如何在代码中配置执行模式：

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setRuntimeMode(RuntimeExecutionMode.BATCH);
```
