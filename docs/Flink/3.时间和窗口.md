# 时间和窗口

## 时间语义

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030238713.png)

Flink 是一个分布式处理系统。分布式架构最大的特点，就是节点彼此独立、互不影响，这带来了更高的吞吐量和容错性，但想要拥有一个全局统一的时钟，在分布式系统里是做不到的。

- **处理时间（Processing Time）**：指执行处理操作的机器的系统时间
- **事件事件（Event Time）**：数据生成的时间，数据一旦产生，这个时间自然就确定了，它通常作为时间戳属性嵌入到数据中

!!!note "事件时间与水位线"

    由于流处理中数据是源源不断产生的，一般来说，先产生的数据也会先被处理，所以当任务不停地接到数据时，它们的时间戳也基本上是不断增长的，就可以**代表时间的推进**。但是，这里有个前提，就是「**先产生的数据先被处理**」，这要求我们可以保证数据到达的顺序。

    但是**由于分布式系统中网络传输延迟的不确定性，实际应用中的数据流往往是乱序的**。在这种情况下，就不能简单地把数据自带的时间戳当作时钟了，而需要用另外的标志来表示事件时间进展，在 Flink 中把它叫作事件时间的「**水位线**」（Watermark）。

!!!note "两种时间语义的对比"

    通常来说，**处理时间是我们计算效率的衡量标准，而事件时间会更符合我们的业务计算逻辑**。

    对于处理时间而言，由于没有任何附加考虑，数据一来就直接处理，因此这种方式可以让我们的流处理延迟降到最低，效率达到最高。所以处理时间语义，一般用在对实时性要求极高、而对计算准确性要求不太高的场景。

    而在事件时间语义下，水位线成为了时钟，可以统一控制时间的进度。这就保证了我们总可以将数据划分到正确的窗口中。所以整体上看，事件时间语义是以一定延迟为代价，换来了处理结果的正确性。

---

## 水位线

在事件时间语义下，我们不依赖系统时间，而是基于数据自带的时间戳去定义了一个时钟，用来表示当前时间的进展。于是**每个并行子任务都会有一个自己的逻辑时钟，它的前进是靠数据的时间戳来驱动的**。

但在分布式系统中，这种驱动方式又会有一些问题。因为数据本身在处理转换的过程中会变化，如果遇到窗口聚合这样的操作，其实是要攒一批数据才会输出一个结果，那么下游的数据就会变少，时间进度的控制就不够精细了。另外，数据向下游任务传递时，一般只能传输给一个子任务（除广播外），这样其他的并行子任务的时钟就无法推进了。例如一个时间戳为 9 点整的数据到来，当前任务的时钟就已经是 9 点了；处理完当前数据要发送到下游，如果下游任务是一个窗口计算，并行度为 3，那么接收到这个数据的子任务，时钟也会进展到 9 点，9 点结束的窗口就可以关闭进行计算了；而另外两个并行子任务则时间没有变化，不能进行窗口计算。

所以我们应该把时钟也以数据的形式传递出去，告诉下游任务当前时间的进展；而且这个时钟的传递不会因为窗口聚合之类的运算而停滞。一种简单的想法是，在数据流中加入一个时钟标记，记录当前的事件时间；这个标记可以直接广播到下游，当下游任务收到这个标记，就可以更新自己的时钟了。由于类似于水流中用来做标志的记号，在 Flink 中，这种用来**衡量事件时间（Event Time）进展的标记**，就被称作**「水位线」（Watermark）**。

具体实现上，水位线可以看作一条特殊的数据记录，它是插入到数据流中的一个标记点，主要内容就是一个时间戳，用来指示当前的事件时间。而它插入流中的位置，就应该是在某个数据到来之后；这样就可以从这个数据中提取时间戳，作为当前水位线的时间戳了。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030257698.png)

---

## 有序流中的水位线

在理想状态下，数据应该按照它们生成的先后顺序、排好队进入流中；也就是说，它们处理的过程会保持原先的顺序不变，遵守先来后到的原则。这样的话我们从每个数据中提取时间戳，就可以保证总是从小到大增长的，从而插入的水位线也会不断增长、事件时钟不断向前推进。

实际应用中，如果当前数据量非常大，可能会有很多数据的时间戳是相同的，这时每来一条数据就提取时间戳、插入水位线就做了大量的无用功。而且即使时间戳不同，同时涌来的数据时间差会非常小（比如几毫秒），往往对处理计算也没什么影响。所以**为了提高效率，一般会每隔一段时间生成一个水位线**，这个水位线的时间戳，就是当前最新数据的时间戳。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030258334.png)

---

## 乱序流中的水位线

在分布式系统中，数据在节点间传输，会因为网络传输延迟的不确定性，导致顺序发生改变，这就是所谓的「乱序数据」。

最直观的想法自然是跟之前一样，我们还是靠数据来驱动，每来一个数据就提取它的时间戳、插入一个水位线。不过现在的情况是数据乱序，所以有可能新的时间戳比之前的还小，如果直接将这个时间的水位线再插入，我们的“时钟”就回退了——水位线就代表了时钟，时光不能倒流，所以水位线的时间戳也不能减小。

解决思路也很简单：我们插入新的水位线时，要**先判断一下时间戳是否比之前的大，否则就不再生成新的水位线**。也就是说，只有数据的时间戳比当前时钟大，才能推动时钟前进，这时才插入水位线。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030301829.png)

这样做尽管可以定义出一个事件时钟，却也会带来一个非常大的问题：**我们无法正确处理「迟到」的数据**。

**解决方案**：我们可以更改一下时钟推进的逻辑：当一个商品到达时，不要直接用它的生产时间作为当前时间，而是减上两秒。即用当前已有数据的最大时间戳减去 2 秒，就是要插入的水位线的时间戳。

> 水位线的默认计算公式：`水位线 = 观察到的最大事件时间 - 最大延迟时间 - 1ms`

---

## 水位线的特性

> 水位线就代表了当前的事件时间时钟，而且可以在数据的时间戳基础上加一些延迟来保证不丢数据，这一点对于乱序流的正确处理非常重要

- 水位线是插入到数据流中的一个标记，可以认为是一个特殊的数据
- 水位线主要的内容是一个时间戳，用来表示当前事件时间的进展
- 水位线是基于数据的时间戳生成的
- 水位线的时间戳必须单调递增，以确保任务的事件时间时钟一直向前推进
- 水位线可以通过设置延迟，来保证正确处理乱序数据
- 一个水位线 Watermark(t)，表示在当前流中事件时间已经达到了时间戳 t, 这代表 t 之前的所有数据都到齐了，之后流中不会出现时间戳 t' ≤ t 的数据

!!! note "水位线的权衡取舍"

    如果我们希望计算结果能更加准确，那可以将水位线的延迟设置得更高一些，等待的时间越长，自然也就越不容易漏掉数据。不过这样做的代价是处理的实时性降低了，我们可能为极少数的迟到数据增加了很多不必要的延迟。

    如果我们希望处理得更快、实时性更强，那么可以将水位线延迟设得低一些。这种情况下，可能很多迟到数据会在水位线之后才到达，就会导致窗口遗漏数据，计算结果不准确。

    所以 **Flink 中的水位线，其实是流处理中对低延迟和结果正确性的一个权衡机制**。

---

## 水位线的传递

实际应用中往往上下游都有多个并行子任务，为了统一推进事件时间的进展，我们要求上游任务处理完水位线、时钟改变之后，要把当前的水位线再次发出，广播给所有的下游子任务。

可是还有另外一个问题，那就是在“重分区”（redistributing）的传输模式下，一个任务有可能会收到来自不同分区上游子任务的数据。而不同分区的子任务时钟并不同步，所以同一时刻发给下游任务的水位线可能并不相同。这时下游任务又该听谁的呢？

这就要回到**水位线定义的本质**了：它表示的是「**当前时间之前的数据，都已经到齐了**」。这是一种保证，告诉下游任务，只要你接到这个水位线，就代表之后我不会再给你发更早的数据了，你可以放心做统计计算而不会遗漏数据。

所以如果一个任务收到了来自上游并行任务的不同的水位线，说明上游各个分区处理得有快有慢，进度各不相同的上游并行子任务都发来了水位线，**应该以慢的那个为准**。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030315960.png)

如上图所示，当前任务的上游，有四个并行子任务，所以会接收到来自四个分区的水位线。而下游有三个并行子任务，所以会向三个分区发出水位线。具体过程如下：

1. 上游并行子任务发来不同的水位线，当前任务会为每一个分区设置一个“**分区水位线**”（Partition Watermark），这是一个分区时钟；而当前任务自己的时钟，就是所有分区时钟里最小的那个。
2. 当有一个新的水位线（第一分区的 4）从上游传来时，当前任务会首先更新对应的分区时钟；然后再次判断所有分区时钟中的最小值，如果比之前大，说明事件时间有了进展，当前任务的时钟也就可以更新了。这里要注意，更新后的任务时钟，并不一定是新来的那个分区水位线，比如这里改变的是第一分区的时钟，但最小的分区时钟是第三分区的 3，于是当前任务时钟就推进到了 3。**当时钟有进展时，当前任务就会将自己的时钟以水位线的形式，广播给下游所有子任务**。
3. 再次收到新的水位线（第二分区的 7）后，执行同样的处理流程。首先将第二个分区时钟更新为 7，然后比较所有分区时钟；发现最小值没有变化，那么当前任务的时钟也不变，也不会向下游任务发出水位线。
4. 同样道理，当又一次收到新的水位线（第三分区的 6）之后，第三个分区时钟更新为 6，同时所有分区时钟最小值变成了第一分区的 4，所以当前任务的时钟推进到 4，并发出时间戳为 4 的水位线，广播到下游各个分区任务。

水位线在上下游任务之间的传递，非常巧妙地避免了分布式系统中没有统一时钟的问题，每个任务都以“处理完之前所有数据”为标准来确定自己的时钟，就可以保证窗口处理的结果总是正确的。

---

## 窗口

把无界流进行切分，每一段数据分别进行聚合，结果只输出一次。这就相当于**将无界流的聚合转化为了有界数据集的聚合**，这就是所谓的「窗口」（Window）聚合操作。

**窗口聚合其实是对实时性和处理效率的一个权衡。**

在 Flink 中, 窗口就是用来处理无界流的核心。我们很容易把窗口想象成一个固定位置的“框”，数据源源不断地流过来，到某个时间点窗口该关闭了，就停止收集数据、触发计算并输出结果。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030326242.png)

对于处理时间下的窗口而言，这样理解似乎没什么问题。然而如果我们采用事件时间语义，由于数据乱序问题，这样理解就有些问题了。由于有乱序数据，我们需要设置一个延迟时间来等所有数据到齐。比如上面的例子中，我们可以设置延迟时间为 2 秒，这样 0~10 秒的窗口会在时间戳为 12 的数据到来之后，才真正关闭计算输出结果，这样就可以正常包含迟到的 9 秒数据了。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030327561.png)

但是这样一来，0~10 秒的窗口不光包含了迟到的 9 秒数据，连 11 秒和 12 秒的数据也包含进去了。我们为了正确处理迟到数据，结果把早到的数据划分到了错误的窗口——最终结果都是错误的。

所以**在 Flink 中，窗口其实并不是一个「框」，相比之下，我们应该把窗口理解成一个「桶」**，如下图所示。在 Flink 中，窗口可以把流切割成有限大小的多个「存储桶」，每个数据都会分发到对应的桶中，当到达窗口结束时间时，就对每个桶中收集的数据进行计算处理。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030329414.png)

我们可以梳理一下事件时间语义下，之前例子中窗口的处理过程：

1. 第一个数据时间戳为 2，判断之后创建第一个窗口 `[0, 10)`，并将 2 秒数据保存进去
2. 后续数据依次到来，时间戳均在 `[0, 10)`范围内，所以全部保存进第一个窗口
3. 11 秒数据到来，判断它不属于`[0, 10)` 窗口，所以创建第二个窗口 `[10, 20)`，并将 11 秒的数据保存进去。由于水位线设置延迟时间为 2 秒，所以现在的时钟是 9 秒，第一个窗口也没有到关闭时间
4. 之后又有 9 秒数据到来，同样进入`[0, 10)` 窗口中
5. 12 秒数据到来，判断属于 `[10, 20)` 窗口，保存进去。这时产生的水位线推进到了 10 秒，所以 `[0, 10)` 窗口应该关闭了。第一个窗口收集到了所有的 7 个数据，进行处理计算后输出结果，并将窗口关闭销毁
6. 同样的，之后的数据依次进入第二个窗口，遇到 20 秒的数据时会创建第三个窗口 `[20, 30)` 并将数据保存进去；遇到 22 秒数据时，水位线达到了 20 秒，第二个窗口触发计算，输出结果并关闭

需要注意的是，**Flink 中窗口并不是静态准备好的，而是动态创建的：当有落在这个窗口区间范围的数据达到时，才创建对应的窗口**。

---

## 窗口类型

窗口的具体实现可以分为 4 类：

- 滚动窗口（Tumbling Window）
- 滑动窗口（Sliding Window）
- 会话窗口（Session Window）
- 全局窗口（Global Window）

[Flink Windows](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/operators/windows/#windows)

---

## 迟到数据的处理
