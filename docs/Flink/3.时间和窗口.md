# 时间和窗口

## 时间语义

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030238713.png)

Flink 是一个分布式处理系统。分布式架构最大的特点，就是节点彼此独立、互不影响，这带来了更高的吞吐量和容错性，但想要拥有一个全局统一的时钟，在分布式系统里是做不到的。

- **处理时间（Processing Time）**：指执行处理操作的机器的系统时间
- **事件事件（Event Time）**：数据生成的时间，数据一旦产生，这个时间自然就确定了，它通常作为时间戳属性嵌入到数据中

!!!note "事件时间与水位线"

    由于流处理中数据是源源不断产生的，一般来说，先产生的数据也会先被处理，所以当任务不停地接到数据时，它们的时间戳也基本上是不断增长的，就可以**代表时间的推进**。但是，这里有个前提，就是「**先产生的数据先被处理**」，这要求我们可以保证数据到达的顺序。

    但是**由于分布式系统中网络传输延迟的不确定性，实际应用中的数据流往往是乱序的**。在这种情况下，就不能简单地把数据自带的时间戳当作时钟了，而需要用另外的标志来表示事件时间进展，在 Flink 中把它叫作事件时间的「**水位线**」（Watermark）。

!!!note "两种时间语义的对比"

    通常来说，**处理时间是我们计算效率的衡量标准，而事件时间会更符合我们的业务计算逻辑**。

    对于处理时间而言，由于没有任何附加考虑，数据一来就直接处理，因此这种方式可以让我们的流处理延迟降到最低，效率达到最高。所以处理时间语义，一般用在对实时性要求极高、而对计算准确性要求不太高的场景。

    而在事件时间语义下，水位线成为了时钟，可以统一控制时间的进度。这就保证了我们总可以将数据划分到正确的窗口中。所以整体上看，事件时间语义是以一定延迟为代价，换来了处理结果的正确性。

---

## 水位线

在事件时间语义下，我们不依赖系统时间，而是基于数据自带的时间戳去定义了一个时钟，用来表示当前时间的进展。于是**每个并行子任务都会有一个自己的逻辑时钟，它的前进是靠数据的时间戳来驱动的**。

但在分布式系统中，这种驱动方式又会有一些问题。因为数据本身在处理转换的过程中会变化，如果遇到窗口聚合这样的操作，其实是要攒一批数据才会输出一个结果，那么下游的数据就会变少，时间进度的控制就不够精细了。另外，数据向下游任务传递时，一般只能传输给一个子任务（除广播外），这样其他的并行子任务的时钟就无法推进了。例如一个时间戳为 9 点整的数据到来，当前任务的时钟就已经是 9 点了；处理完当前数据要发送到下游，如果下游任务是一个窗口计算，并行度为 3，那么接收到这个数据的子任务，时钟也会进展到 9 点，9 点结束的窗口就可以关闭进行计算了；而另外两个并行子任务则时间没有变化，不能进行窗口计算。

所以我们应该把时钟也以数据的形式传递出去，告诉下游任务当前时间的进展；而且这个时钟的传递不会因为窗口聚合之类的运算而停滞。一种简单的想法是，在数据流中加入一个时钟标记，记录当前的事件时间；这个标记可以直接广播到下游，当下游任务收到这个标记，就可以更新自己的时钟了。由于类似于水流中用来做标志的记号，在 Flink 中，这种用来**衡量事件时间（Event Time）进展的标记**，就被称作**「水位线」（Watermark）**。

具体实现上，水位线可以看作一条特殊的数据记录，它是插入到数据流中的一个标记点，主要内容就是一个时间戳，用来指示当前的事件时间。而它插入流中的位置，就应该是在某个数据到来之后；这样就可以从这个数据中提取时间戳，作为当前水位线的时间戳了。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030257698.png)

---

## 有序流中的水位线

在理想状态下，数据应该按照它们生成的先后顺序、排好队进入流中；也就是说，它们处理的过程会保持原先的顺序不变，遵守先来后到的原则。这样的话我们从每个数据中提取时间戳，就可以保证总是从小到大增长的，从而插入的水位线也会不断增长、事件时钟不断向前推进。

实际应用中，如果当前数据量非常大，可能会有很多数据的时间戳是相同的，这时每来一条数据就提取时间戳、插入水位线就做了大量的无用功。而且即使时间戳不同，同时涌来的数据时间差会非常小（比如几毫秒），往往对处理计算也没什么影响。所以**为了提高效率，一般会每隔一段时间生成一个水位线**，这个水位线的时间戳，就是当前最新数据的时间戳。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030258334.png)

---

## 乱序流中的水位线

在分布式系统中，数据在节点间传输，会因为网络传输延迟的不确定性，导致顺序发生改变，这就是所谓的「乱序数据」。

最直观的想法自然是跟之前一样，我们还是靠数据来驱动，每来一个数据就提取它的时间戳、插入一个水位线。不过现在的情况是数据乱序，所以有可能新的时间戳比之前的还小，如果直接将这个时间的水位线再插入，我们的“时钟”就回退了——水位线就代表了时钟，时光不能倒流，所以水位线的时间戳也不能减小。

解决思路也很简单：我们插入新的水位线时，要**先判断一下时间戳是否比之前的大，否则就不再生成新的水位线**。也就是说，只有数据的时间戳比当前时钟大，才能推动时钟前进，这时才插入水位线。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030301829.png)

这样做尽管可以定义出一个事件时钟，却也会带来一个非常大的问题：**我们无法正确处理「迟到」的数据**。

**解决方案**：我们可以更改一下时钟推进的逻辑：当一个商品到达时，不要直接用它的生产时间作为当前时间，而是减上两秒。即用当前已有数据的最大时间戳减去 2 秒，就是要插入的水位线的时间戳。

> 水位线的默认计算公式：`水位线 = 观察到的最大事件时间 - 最大延迟时间 - 1ms`

---

## 水位线的特性

> 水位线就代表了当前的事件时间时钟，而且可以在数据的时间戳基础上加一些延迟来保证不丢数据，这一点对于乱序流的正确处理非常重要

- 水位线是插入到数据流中的一个标记，可以认为是一个特殊的数据
- 水位线主要的内容是一个时间戳，用来表示当前事件时间的进展
- 水位线是基于数据的时间戳生成的
- 水位线的时间戳必须单调递增，以确保任务的事件时间时钟一直向前推进
- 水位线可以通过设置延迟，来保证正确处理乱序数据
- 一个水位线 Watermark(t)，表示在当前流中事件时间已经达到了时间戳 t, 这代表 t 之前的所有数据都到齐了，之后流中不会出现时间戳 t' ≤ t 的数据

!!! note "水位线的权衡取舍"

    如果我们希望计算结果能更加准确，那可以将水位线的延迟设置得更高一些，等待的时间越长，自然也就越不容易漏掉数据。不过这样做的代价是处理的实时性降低了，我们可能为极少数的迟到数据增加了很多不必要的延迟。

    如果我们希望处理得更快、实时性更强，那么可以将水位线延迟设得低一些。这种情况下，可能很多迟到数据会在水位线之后才到达，就会导致窗口遗漏数据，计算结果不准确。

    所以 **Flink 中的水位线，其实是流处理中对低延迟和结果正确性的一个权衡机制**。

---

## 水位线的传递

实际应用中往往上下游都有多个并行子任务，为了统一推进事件时间的进展，我们要求上游任务处理完水位线、时钟改变之后，要把当前的水位线再次发出，广播给所有的下游子任务。

可是还有另外一个问题，那就是在“重分区”（redistributing）的传输模式下，一个任务有可能会收到来自不同分区上游子任务的数据。而不同分区的子任务时钟并不同步，所以同一时刻发给下游任务的水位线可能并不相同。这时下游任务又该听谁的呢？

这就要回到**水位线定义的本质**了：它表示的是「**当前时间之前的数据，都已经到齐了**」。这是一种保证，告诉下游任务，只要你接到这个水位线，就代表之后我不会再给你发更早的数据了，你可以放心做统计计算而不会遗漏数据。

所以如果一个任务收到了来自上游并行任务的不同的水位线，说明上游各个分区处理得有快有慢，进度各不相同的上游并行子任务都发来了水位线，**应该以慢的那个为准**。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030315960.png)

如上图所示，当前任务的上游，有四个并行子任务，所以会接收到来自四个分区的水位线。而下游有三个并行子任务，所以会向三个分区发出水位线。具体过程如下：

1. 上游并行子任务发来不同的水位线，当前任务会为每一个分区设置一个“**分区水位线**”（Partition Watermark），这是一个分区时钟；而当前任务自己的时钟，就是所有分区时钟里最小的那个。
2. 当有一个新的水位线（第一分区的 4）从上游传来时，当前任务会首先更新对应的分区时钟；然后再次判断所有分区时钟中的最小值，如果比之前大，说明事件时间有了进展，当前任务的时钟也就可以更新了。这里要注意，更新后的任务时钟，并不一定是新来的那个分区水位线，比如这里改变的是第一分区的时钟，但最小的分区时钟是第三分区的 3，于是当前任务时钟就推进到了 3。**当时钟有进展时，当前任务就会将自己的时钟以水位线的形式，广播给下游所有子任务**。
3. 再次收到新的水位线（第二分区的 7）后，执行同样的处理流程。首先将第二个分区时钟更新为 7，然后比较所有分区时钟；发现最小值没有变化，那么当前任务的时钟也不变，也不会向下游任务发出水位线。
4. 同样道理，当又一次收到新的水位线（第三分区的 6）之后，第三个分区时钟更新为 6，同时所有分区时钟最小值变成了第一分区的 4，所以当前任务的时钟推进到 4，并发出时间戳为 4 的水位线，广播到下游各个分区任务。

水位线在上下游任务之间的传递，非常巧妙地避免了分布式系统中没有统一时钟的问题，每个任务都以“处理完之前所有数据”为标准来确定自己的时钟，就可以保证窗口处理的结果总是正确的。

---

## Watermark Strategy

为了使用事件时间语义，Flink 应用程序需要知道事件时间戳对应的字段，意味着数据流中的每个元素都需要拥有可分配的事件时间戳。其通常通过使用 TimestampAssigner API 从元素中的某个字段去访问/提取时间戳。

时间戳的分配与 watermark 的生成是齐头并进的，其可以告诉 Flink 应用程序事件时间的进度。其可以通过指定 WatermarkGenerator 来配置 watermark 的生成方式。

使用 Flink API 时需要设置一个同时包含 TimestampAssigner 和 WatermarkGenerator 的 WatermarkStrategy。WatermarkStrategy 工具类中也提供了许多常用的 watermark 策略，并且用户也可以在某些必要场景下构建自己的 watermark 策略。WatermarkStrategy 接口如下：

```java
public interface WatermarkStrategy<T>
    extends TimestampAssignerSupplier<T>, WatermarkGeneratorSupplier<T>{

    /**
     * 根据策略实例化一个可分配时间戳的 TimestampAssigner。
     */
    @Override
    TimestampAssigner<T> createTimestampAssigner(TimestampAssignerSupplier.Context context);

    /**
     * 根据策略实例化一个 watermark 生成器。
     */
    @Override
    WatermarkGenerator<T> createWatermarkGenerator(WatermarkGeneratorSupplier.Context context);
}
```

如上所述，通常情况下，你不用实现此接口，而是可以使用 WatermarkStrategy 工具类中通用的 watermark 策略，或者可以使用这个工具类将自定义的 TimestampAssigner 与 WatermarkGenerator 进行绑定。例如，你想要要使用有界无序（bounded-out-of-orderness）watermark 生成器和一个 lambda 表达式作为时间戳分配器，那么可以按照如下方式实现：

```java
WatermarkStrategy
        .<Tuple2<Long, String>>forBoundedOutOfOrderness(Duration.ofSeconds(20))
        .withTimestampAssigner((event, timestamp) -> event.f0);
```

---

WatermarkStrategy 可以在 Flink 应用程序中的两处使用，第一种是直接在数据源上使用，第二种是直接在非数据源的操作之后使用。

第一种方式相比会更好，因为数据源可以利用 watermark 生成逻辑中有关分片/分区（shards/partitions/splits）的信息。使用这种方式，数据源通常可以更精准地跟踪 watermark，整体 watermark 生成将更精确。直接在源上指定 WatermarkStrategy 意味着你必须使用特定数据源接口。

仅当无法直接在数据源上设置策略时，才应该使用第二种方式（在任意转换操作之后设置 WatermarkStrategy）：

```java hl_lines="7"
DataStream<MyEvent> stream = env.readFile(
        myFormat, myFilePath, FileProcessingMode.PROCESS_CONTINUOUSLY, 100,
        FilePathFilter.createDefaultFilter(), typeInfo);

DataStream<MyEvent> withTimestampsAndWatermarks = stream
        .filter( event -> event.severity() == WARNING )
        .assignTimestampsAndWatermarks(<watermark strategy>);

withTimestampsAndWatermarks
        .keyBy( (event) -> event.getGroup() )
        .window(TumblingEventTimeWindows.of(Time.seconds(10)))
        .reduce( (a, b) -> a.add(b) )
        .addSink(...);
```

使用 WatermarkStrategy 去获取流并生成带有时间戳的元素和 watermark 的新流时，如果原始流已经具有时间戳或 watermark，则新指定的时间戳分配器将覆盖原有的时间戳和 watermark。

---

## 处理空闲数据源

如果数据源中的某一个分区/分片在一段时间内未发送事件数据，则意味着 WatermarkGenerator 也不会获得任何新数据去生成 watermark。我们称这类数据源为空闲输入或空闲源。在这种情况下，当某些其他分区仍然发送事件数据的时候就会出现问题。由于下游算子 watermark 的计算方式是取所有不同的上游并行数据源 watermark 的最小值，则其 watermark 将不会发生变化。

为了解决这个问题，你可以使用 WatermarkStrategy 来检测空闲输入并将其标记为空闲状态。WatermarkStrategy 为此提供了一个工具接口：

```java hl_lines="3"
WatermarkStrategy
        .<Tuple2<Long, String>>forBoundedOutOfOrderness(Duration.ofSeconds(20))
        .withIdleness(Duration.ofMinutes(1));
```

---

## 自定义 WatermarkGenerator

TimestampAssigner 是一个可以从事件数据中提取时间戳字段的简单函数，我们无需详细查看其实现。但是 WatermarkGenerator 的编写相对就要复杂一些了，WatermarkGenerator 接口代码如下：

```java
/**
 * 可以基于事件或者周期性的生成 watermark。
 *
 * 注意：WatermarkGenerator 将以前互相独立的 AssignerWithPunctuatedWatermarks
 * 和 AssignerWithPeriodicWatermarks 一同包含了进来。
 */
@Public
public interface WatermarkGenerator<T> {

    /**
     * 每来一条事件数据调用一次，可以检查或者记录事件的时间戳，或者也可以基于事件数据本身去生成 watermark。
     */
    void onEvent(T event, long eventTimestamp, WatermarkOutput output);

    /**
     * 周期性的调用，也许会生成新的 watermark，也许不会。
     *
     * 调用此方法生成 watermark 的间隔时间由 ExecutionConfig#getAutoWatermarkInterval() 决定。
     */
    void onPeriodicEmit(WatermarkOutput output);
}
```

watermark 的生成方式本质上是有两种：**周期性生成**和**标记生成**。

周期性生成器通常通过 `onEvent()` 观察传入的事件数据，然后在框架调用 `onPeriodicEmit()` 时发出 watermark。

标记生成器将查看 `onEvent()` 中的事件数据，并等待检查在流中携带 watermark 的特殊标记事件或打点数据。当获取到这些事件数据时，它将立即发出 watermark。通常情况下，标记生成器不会通过 `onPeriodicEmit()` 发出 watermark。

---

### 自定义周期性 Watermark 生成器

周期性生成器会观察流事件数据并定期生成 watermark（其生成可能取决于流数据，或者完全基于处理时间）。

生成 watermark 的时间间隔（每 n 毫秒）可以通过 `ExecutionConfig.setAutoWatermarkInterval(...)` 指定。每次都会调用生成器的 `onPeriodicEmit()` 方法，如果返回的 watermark 非空且值大于前一个 watermark，则将发出新的 watermark。

如下是两个使用周期性 watermark 生成器的简单示例。

```java
/**
 * 该 watermark 生成器可以覆盖的场景是：数据源在一定程度上乱序。
 * 即某个最新到达的时间戳为 t 的元素将在最早到达的时间戳为 t 的元素之后最多 n 毫秒到达。
 */
public class BoundedOutOfOrdernessGenerator implements WatermarkGenerator<MyEvent> {

    private final long maxOutOfOrderness = 3500; // 3.5 秒

    private long currentMaxTimestamp;

    @Override
    public void onEvent(MyEvent event, long eventTimestamp, WatermarkOutput output) {
        currentMaxTimestamp = Math.max(currentMaxTimestamp, eventTimestamp);
    }

    @Override
    public void onPeriodicEmit(WatermarkOutput output) {
        // 发出的 watermark = 当前最大时间戳 - 最大乱序时间
        output.emitWatermark(new Watermark(currentMaxTimestamp - maxOutOfOrderness - 1));
    }

}
```

```java
/**
 * 该生成器生成的 watermark 滞后于处理时间固定量。它假定元素会在有限延迟后到达 Flink。
 */
public class TimeLagWatermarkGenerator implements WatermarkGenerator<MyEvent> {

    private final long maxTimeLag = 5000; // 5 秒

    @Override
    public void onEvent(MyEvent event, long eventTimestamp, WatermarkOutput output) {
        // 处理时间场景下不需要实现
    }

    @Override
    public void onPeriodicEmit(WatermarkOutput output) {
        output.emitWatermark(new Watermark(System.currentTimeMillis() - maxTimeLag));
    }
}
```

---

### 自定义标记 Watermark 生成器

标记 watermark 生成器观察流事件数据并在获取到带有 watermark 信息的特殊事件元素时发出 watermark。

如下是实现标记生成器的方法，当事件带有某个指定标记时，该生成器就会发出 watermark：

```java
public class PunctuatedAssigner implements WatermarkGenerator<MyEvent> {

    @Override
    public void onEvent(MyEvent event, long eventTimestamp, WatermarkOutput output) {
        if (event.hasWatermarkMarker()) {
            output.emitWatermark(new Watermark(event.getWatermarkTimestamp()));
        }
    }

    @Override
    public void onPeriodicEmit(WatermarkOutput output) {
        // onEvent 中已经实现
    }
}
```

注意： 可以针对每个事件去生成 watermark。但是由于每个 watermark 都会在下游做一些计算，因此过多的 watermark 会降低程序性能。

---

### 内置 Watermark 生成器

Flink 提供的抽象方法可以允许用户自己去定义时间戳分配方式和 watermark 生成的方式。你可以通过实现 WatermarkGenerator 接口来实现上述功能。

为了进一步简化此类任务的编程工作，Flink 框架预设了一些时间戳分配器。

**单调递增时间戳分配器**

周期性 watermark 生成方式的一个最简单特例就是你给定的数据源中数据的时间戳升序出现。在这种情况下，当前时间戳就可以充当 watermark，因为后续到达数据的时间戳不会比当前的小。

注意：在 Flink 应用程序中，如果是并行数据源，则只要求并行数据源中的每个单分区数据源任务时间戳递增。例如，设置每一个并行数据源实例都只读取一个 Kafka 分区，则时间戳只需在每个 Kafka 分区内递增即可。Flink 的 watermark 合并机制会在并行数据流进行分发（shuffle）、联合（union）、连接（connect）或合并（merge）时生成正确的 watermark。

```java
WatermarkStrategy.forMonotonousTimestamps();
```

**数据之间存在最大固定延迟的时间戳分配器**

另一个周期性 watermark 生成的典型例子是，watermark 滞后于数据流中最大（事件时间）时间戳一个固定的时间量。该示例可以覆盖的场景是你预先知道数据流中的数据可能遇到的最大延迟。

```java
WatermarkStrategy.forBoundedOutOfOrderness(Duration.ofSeconds(10));
```

---

## 窗口

把无界流进行切分，每一段数据分别进行聚合，结果只输出一次。这就相当于**将无界流的聚合转化为了有界数据集的聚合**，这就是所谓的「窗口」（Window）聚合操作。

**窗口聚合其实是对实时性和处理效率的一个权衡。**

在 Flink 中, 窗口就是用来处理无界流的核心。我们很容易把窗口想象成一个固定位置的“框”，数据源源不断地流过来，到某个时间点窗口该关闭了，就停止收集数据、触发计算并输出结果。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030326242.png)

对于处理时间下的窗口而言，这样理解似乎没什么问题。然而如果我们采用事件时间语义，由于数据乱序问题，这样理解就有些问题了。由于有乱序数据，我们需要设置一个延迟时间来等所有数据到齐。比如上面的例子中，我们可以设置延迟时间为 2 秒，这样 0~10 秒的窗口会在时间戳为 12 的数据到来之后，才真正关闭计算输出结果，这样就可以正常包含迟到的 9 秒数据了。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030327561.png)

但是这样一来，0~10 秒的窗口不光包含了迟到的 9 秒数据，连 11 秒和 12 秒的数据也包含进去了。我们为了正确处理迟到数据，结果把早到的数据划分到了错误的窗口——最终结果都是错误的。

所以**在 Flink 中，窗口其实并不是一个「框」，相比之下，我们应该把窗口理解成一个「桶」**，如下图所示。在 Flink 中，窗口可以把流切割成有限大小的多个「存储桶」，每个数据都会分发到对应的桶中，当到达窗口结束时间时，就对每个桶中收集的数据进行计算处理。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410030329414.png)

我们可以梳理一下事件时间语义下，之前例子中窗口的处理过程：

1. 第一个数据时间戳为 2，判断之后创建第一个窗口 `[0, 10)`，并将 2 秒数据保存进去
2. 后续数据依次到来，时间戳均在 `[0, 10)`范围内，所以全部保存进第一个窗口
3. 11 秒数据到来，判断它不属于`[0, 10)` 窗口，所以创建第二个窗口 `[10, 20)`，并将 11 秒的数据保存进去。由于水位线设置延迟时间为 2 秒，所以现在的时钟是 9 秒，第一个窗口也没有到关闭时间
4. 之后又有 9 秒数据到来，同样进入`[0, 10)` 窗口中
5. 12 秒数据到来，判断属于 `[10, 20)` 窗口，保存进去。这时产生的水位线推进到了 10 秒，所以 `[0, 10)` 窗口应该关闭了。第一个窗口收集到了所有的 7 个数据，进行处理计算后输出结果，并将窗口关闭销毁
6. 同样的，之后的数据依次进入第二个窗口，遇到 20 秒的数据时会创建第三个窗口 `[20, 30)` 并将数据保存进去；遇到 22 秒数据时，水位线达到了 20 秒，第二个窗口触发计算，输出结果并关闭

需要注意的是，**Flink 中窗口并不是静态准备好的，而是动态创建的：当有落在这个窗口区间范围的数据达到时，才创建对应的窗口**。

---

## 窗口类型

!!! note "窗口分配器（Window Assigner）"

    窗口分配器（Window Assigner）是决定一个元素属于哪个窗口的核心组件。Flink 为最常用的情况提供了一些定义好的 window assigner，也就是 tumbling windows、sliding windows、session windows 和 global windows。你也可以继承 WindowAssigner 类来实现自定义的 window assigner。所有内置的 window assigner（除了 global window）都是基于时间分发数据的，processing time 或 event time 均可。

窗口的具体实现可以分为 4 类：

- 滚动窗口（Tumbling Window）
- 滑动窗口（Sliding Window）
- 会话窗口（Session Window）
- 全局窗口（Global Window）

---

### 滚动窗口（Tumbling Window）

滚动窗口有固定的大小，是一种对数据进行**均匀切片**的划分方式。**窗口之间没有重叠，也不会有间隔**，是首尾相接的状态。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410031547217.png)

```java
DataStream<T> input = ...;

// 滚动 event-time 窗口
input
    .keyBy(<key selector>)
    .window(TumblingEventTimeWindows.of(Time.seconds(5)))
    .<windowed transformation>(<window function>);

// 滚动 processing-time 窗口
input
    .keyBy(<key selector>)
    .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))
    .<windowed transformation>(<window function>);

// 长度为一天的滚动 event-time 窗口， 偏移量为 -8 小时。
input
    .keyBy(<key selector>)
    .window(TumblingEventTimeWindows.of(Time.days(1), Time.hours(-8)))
    .<windowed transformation>(<window function>);
```

如上一个例子所示，滚动窗口的 assigners 也可以传入可选的 offset 参数。这个参数可以用来对齐窗口。

比如说，不设置 offset 时，长度为一小时的滚动窗口会与 Linux 的 epoch 对齐。你会得到如下时间段：

- 1:00:00.000 - 1:59:59.999
- 2:00:00.000 - 2:59:59.999

如果你想改变对齐方式，可以设置一个 offset。如果设置了 15 分钟的 offset，你会得到：

- 1:15:00.000 - 2:14:59.999
- 2:15:00.000 - 3:14:59.999

一个重要的 offset 用例是根据 UTC-0 调整窗口的时差。例如，在中国，你可能会设置 offset 为 `Time.hours(-8)`。

---

### 滑动窗口（Sliding Window）

与滚动窗口类似，滑动窗口的大小也是固定的。区别在于，窗口之间并不是首尾相接的，而是可以「错开」一定的位置。定义滑动窗口的参数有两
个：**窗口大小**和**滑动步长**。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410031552946.png)

```java
DataStream<T> input = ...;

// 滑动 event-time 窗口
input
    .keyBy(<key selector>)
    .window(SlidingEventTimeWindows.of(Time.seconds(10), Time.seconds(5)))
    .<windowed transformation>(<window function>);

// 滑动 processing-time 窗口
input
    .keyBy(<key selector>)
    .window(SlidingProcessingTimeWindows.of(Time.seconds(10), Time.seconds(5)))
    .<windowed transformation>(<window function>);

// 滑动 processing-time 窗口，偏移量为 -8 小时
input
    .keyBy(<key selector>)
    .window(SlidingProcessingTimeWindows.of(Time.hours(12), Time.hours(1), Time.hours(-8)))
    .<windowed transformation>(<window function>);
```

---

### 会话窗口（Session Window）

会话窗口的 assigner 会把数据按活跃的会话分组。与滚动窗口和滑动窗口不同，会话窗口不会相互重叠，且没有固定的开始或结束时间。

会话窗口在一段时间没有收到数据之后会关闭，即在一段不活跃的间隔之后。会话窗口的 assigner 可以设置固定的会话间隔（session gap）或使用 session gap extractor 函数来动态地定义多长时间算作不活跃。

当超出了不活跃的时间段，当前的会话就会关闭，并且将接下来的数据分发到新的会话窗口。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410031553378.png)

```java
DataStream<T> input = ...;

// 设置了固定间隔的 event-time 会话窗口
input
    .keyBy(<key selector>)
    .window(EventTimeSessionWindows.withGap(Time.minutes(10)))
    .<windowed transformation>(<window function>);

// 设置了动态间隔的 event-time 会话窗口
input
    .keyBy(<key selector>)
    .window(EventTimeSessionWindows.withDynamicGap((element) -> {
        // 决定并返回会话间隔
    }))
    .<windowed transformation>(<window function>);

// 设置了固定间隔的 processing-time session 窗口
input
    .keyBy(<key selector>)
    .window(ProcessingTimeSessionWindows.withGap(Time.minutes(10)))
    .<windowed transformation>(<window function>);

// 设置了动态间隔的 processing-time 会话窗口
input
    .keyBy(<key selector>)
    .window(ProcessingTimeSessionWindows.withDynamicGap((element) -> {
        // 决定并返回会话间隔
    }))
    .<windowed transformation>(<window function>);
```

!!! note

    会话窗口并没有固定的开始或结束时间，所以它的计算方法与滑动窗口和滚动窗口不同。在 Flink 内部，会话窗口的算子会为每一条数据创建一个窗口， 然后将距离不超过预设间隔的窗口合并。想要让窗口可以被合并，会话窗口需要拥有支持合并的 Trigger 和 Window Function， 比如说 ReduceFunction、AggregateFunction 或 ProcessWindowFunction。

---

### 全局窗口（Global Window）

全局窗口全局有效，会把相同 key 的所有数据都分配到同一个窗口中，就跟没分窗口一样。这样的窗口模式仅在你指定了自定义的 trigger 时有用。无界流的数据永无止尽，所以这种窗口也没有结束的时候，默认是不会做触发计算的。如果希望它能对数据进行计算处理，还需要自定义「触发器」（Trigger）。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410031555130.png)

```java
DataStream<T> input = ...;

input
    .keyBy(<key selector>)
    .window(GlobalWindows.create())
    .<windowed transformation>(<window function>);
```

---

## 窗口的生命周期

简单来说，**一个窗口在第一个属于它的元素到达时就会被创建**，然后在时间（event 或 processing time） 超过窗口的「结束时间戳 + 用户定义的 allowed lateness」时被完全删除。Flink 仅保证删除基于时间的窗口，其他类型的窗口不做保证，比如全局窗口。 例如，对于一个基于 event time 且范围互不重合（滚动）的窗口策略，如果窗口设置的时长为五分钟、可容忍的迟到时间（allowed lateness）为 1 分钟， 那么第一个元素落入 12:00 至 12:05 这个区间时，Flink 就会为这个区间创建一个新的窗口。当 watermark 越过 12:06 时，这个窗口将被摧毁。

另外，每个窗口会设置自己的 Trigger 和 function（ProcessWindowFunction、ReduceFunction、或 AggregateFunction）。function 决定如何计算窗口中的内容， 而 Trigger 决定何时窗口中的数据可以被 function 计算。Trigger 的触发（fire）条件可能是“当窗口中有多于 4 条数据”或“当 watermark 越过窗口的结束时间”等。Trigger 还可以在 window 被创建后、删除前的这段时间内定义何时清理（purge）窗口中的数据。这里的数据仅指窗口内的元素，不包括窗口的 meta data。也就是说，窗口在 purge 后仍然可以加入新的数据。

除此之外，你也可以指定一个 Evictor，在 trigger 触发之后，Evictor 可以在窗口函数的前后删除数据。

---

## 窗口的计算机制

^^I. 窗口的创建^^

: 窗口的类型和基本信息由**窗口分配器（Window Assigner）**指定，窗口分配器会根据每一条输入数据的时间（处理时间或事件时间）、窗口大小等参数来决定将这条数据分配到哪个时间范围的窗口中。

: 需要注意的是，窗口不会预先创建好，而是由数据驱动创建。当第一个应该属于这个窗口的数据元素到达时，就会创建对应的窗口。

^^II. 窗口计算的触发^^

: 除了窗口分配器，每个窗口还会有自己的窗口函数（Window Function）和触发器（Trigger）。窗口函数可以分为增量聚合函数和全窗口函数，主要定义了窗口中计算的逻辑；而触发器是通过定时器来触发窗口计算的，大多数情况下窗口触发计算的时间都是窗口结束的时间。

: 对于不同的窗口类型，触发计算的条件也会不同。例如，一个滚动事件时间窗口，应该在水位线到达窗口结束时间的时候触发计算。而一个计数窗口，会在窗口中元素数量达到定义大小时触发计算。所有 Flink 预定义的窗口类型都有对应内置的触发器。

: 当我们设置了允许延迟，那么如果水位线超过了窗口结束时间、但还没有到达设定的最大延迟时间，这期间内到达的迟到数据也会触发窗口计算。

^^III. 窗口的销毁^^

: 一般情况下，当时间达到了结束点，就会直接触发计算输出结果、进而清除状态销毁窗口。这时窗口的销毁可以认为和触发计算是同一时刻。这里需要注意，**Flink 中只对时间窗口有销毁机制**。由于计数窗口是基于全局窗口实现的，而全局窗口不会清除状态，所以就不会被销毁。

: 在特殊的场景下，窗口的销毁和触发计算会有所不同。事件时间语义下，如果设置了允许延迟，那么在水位线到达窗口结束时间时，仍然不会销毁窗口；**窗口真正被完全删除的时间点，是窗口的结束时间加上用户指定的允许延迟时间**。

---

## 窗口 API 调用总结

=== "Keyed Windows"

    ```java
    stream
        .keyBy(...)               <-  仅 keyed 窗口需要
        .window(...)              <-  必填项："assigner"
        [.trigger(...)]            <-  可选项："trigger" (省略则使用默认 trigger)
        [.evictor(...)]            <-  可选项："evictor" (省略则不使用 evictor)
        [.allowedLateness(...)]    <-  可选项："lateness" (省略则为 0)
        [.sideOutputLateData(...)] <-  可选项："output tag" (省略则不对迟到数据使用 side output)
        .reduce/aggregate/apply()      <-  必填项："function"
        [.getSideOutput(...)]      <-  可选项："output tag"
    ```

=== "Non-Keyed Windows"

    ```java
    stream
        .windowAll(...)           <-  必填项："assigner"
        [.trigger(...)]            <-  可选项："trigger" (else default trigger)
        [.evictor(...)]            <-  可选项："evictor" (else no evictor)
        [.allowedLateness(...)]    <-  可选项："lateness" (else zero)
        [.sideOutputLateData(...)] <-  可选项："output tag" (else no side output for late data)
        .reduce/aggregate/apply()      <-  必填项："function"
        [.getSideOutput(...)]      <-  可选项："output tag"
    ```

Window API 首先按照时候按键分区分成两类：

- keyBy 之后的 KeyedStream，可以调用 `.window()` 方法声明按键分区窗口（Keyed Windows）
- 如果不做 keyBy，DataStream 也可以直接调用 `.windowAll()` 声明非按键分区窗口，之后的方法调用就完全一样了

接下来通过各类转换方法（reduce/aggregate/apply/process）给出窗口函数(ReduceFunction/AggregateFunction/ProcessWindowFunction)，定义窗口的具体计算处理逻辑，转换之后重新得到 DataStream。这两者必不可少，是窗口算子（WindowOperator）最重要的组成部分。

此外，在这两者之间，还可以基于 WindowedStream 调用 `.trigger()` 自定义触发器、调用 `.evictor()` 定义移除器、调用 `.allowedLateness()` 指定允许延迟时间、调用 `.sideOutputLateData()` 将迟到数据写入侧输出流，这些都是可选的 API，一般不需要实现。而如果定义了侧输出流，可以基于窗口聚合之后的 DataStream 调用 `.getSideOutput()` 获取侧输出流。

---

## 窗口函数（Window Functions）

定义了 window assigner 之后，我们需要指定当窗口触发之后，如何计算每个窗口中的数据，这就是 window function 的职责了。关于窗口如何触发，详见 triggers。

窗口函数有三种：ReduceFunction、AggregateFunction 和 ProcessWindowFunction。前两者执行起来更高效（详见 State Size）因为 Flink 可以在每条数据到达窗口后进行**增量聚合（incrementally aggregate）**。 而 ProcessWindowFunction 会得到能够遍历当前窗口内所有数据的 Iterable，以及关于这个窗口的 meta-information。

使用 ProcessWindowFunction 的窗口转换操作没有其他两种函数高效，因为 Flink 在窗口触发前必须**缓存里面的所有数据**。ProcessWindowFunction 可以与 ReduceFunction 或 AggregateFunction 合并来提高效率。 这样做既可以增量聚合窗口内的数据，又可以从 ProcessWindowFunction 接收窗口的 metadata。

---

### ReduceFunction

ReduceFunction 指定两条输入数据如何合并起来产生一条输出数据，输入和输出数据的类型必须相同。Flink 使用 ReduceFunction 对窗口中的数据进行增量聚合。

```java
DataStream<Tuple2<String, Long>> input = ...;

input
    .keyBy(<key selector>)
    .window(<window assigner>)
    .reduce(new ReduceFunction<Tuple2<String, Long>>() {
      public Tuple2<String, Long> reduce(Tuple2<String, Long> v1, Tuple2<String, Long> v2) {
        return new Tuple2<>(v1.f0, v1.f1 + v2.f1);
      }
    });
```

上面的例子是对窗口内元组的第二个属性求和。

---

### AggregateFunction

ReduceFunction 是 AggregateFunction 的特殊情况。AggregateFunction 接收三个类型：**输入数据的类型(IN)、累加器的类型（ACC）和输出数据的类型（OUT）**。输入数据的类型是输入流的元素类型，AggregateFunction 接口有如下几个方法：

- 创建初始累加器
- 把每一条元素加进累加器
- 合并两个累加器
- 从累加器中提取输出（OUT 类型）

与 ReduceFunction 相同，Flink 会在输入数据到达窗口时直接进行增量聚合。

```java
/**
 * The accumulator is used to keep a running sum and a count. The getResult method
 * computes the average.
 */
private static class AverageAggregate
    implements AggregateFunction<Tuple2<String, Long>, Tuple2<Long, Long>, Double> {
  @Override
  public Tuple2<Long, Long> createAccumulator() {
    return new Tuple2<>(0L, 0L);
  }

  @Override
  public Tuple2<Long, Long> add(Tuple2<String, Long> value, Tuple2<Long, Long> accumulator) {
    return new Tuple2<>(accumulator.f0 + value.f1, accumulator.f1 + 1L);
  }

  @Override
  public Double getResult(Tuple2<Long, Long> accumulator) {
    return ((double) accumulator.f0) / accumulator.f1;
  }

  @Override
  public Tuple2<Long, Long> merge(Tuple2<Long, Long> a, Tuple2<Long, Long> b) {
    return new Tuple2<>(a.f0 + b.f0, a.f1 + b.f1);
  }
}

DataStream<Tuple2<String, Long>> input = ...;

input
    .keyBy(<key selector>)
    .window(<window assigner>)
    .aggregate(new AverageAggregate());
```

上例计算了窗口内所有元素第二个属性的平均值。

---

### ProcessWindowFunction

ProcessWindowFunction 有能获取包含窗口内所有元素的 Iterable，以及用来获取时间和状态信息的 Context 对象，比其他窗口函数更加灵活。 ProcessWindowFunction 的灵活性是以性能和资源消耗为代价的，因为**窗口中的数据无法被增量聚合**，而需要在窗口触发前缓存所有数据。

```java
DataStream<Tuple2<String, Long>> input = ...;

input
  .keyBy(t -> t.f0)
  .window(TumblingEventTimeWindows.of(Time.minutes(5)))
  .process(new MyProcessWindowFunction());

/* ... */

public class MyProcessWindowFunction
    extends ProcessWindowFunction<Tuple2<String, Long>, String, String, TimeWindow> {

  @Override
  public void process(String key, Context context, Iterable<Tuple2<String, Long>> input, Collector<String> out) {
    long count = 0;
    for (Tuple2<String, Long> in: input) {
      count++;
    }
    out.collect("Window: " + context.window() + "count: " + count);
  }
}
```

上例使用 ProcessWindowFunction 对窗口中的元素计数，并且将窗口本身的信息一同输出。注意，使用 ProcessWindowFunction 完成简单的聚合任务是非常低效的。

---

### 增量聚合的 ProcessWindowFunction

ProcessWindowFunction 可以与 ReduceFunction 或 AggregateFunction 搭配使用，使其能够在数据到达窗口的时候进行增量聚合。当窗口关闭时，ProcessWindowFunction 将会得到聚合的结果。这样它就可以增量聚合窗口的元素并且从 ProcessWindowFunction 中获得窗口的元数据。

下例展示了如何将 ReduceFunction 与 ProcessWindowFunction 组合，返回窗口中的最小元素和窗口的开始时间。

```java
DataStream<SensorReading> input = ...;

input
  .keyBy(<key selector>)
  .window(<window assigner>)
  .reduce(new MyReduceFunction(), new MyProcessWindowFunction());

// Function definitions

private static class MyReduceFunction implements ReduceFunction<SensorReading> {

  public SensorReading reduce(SensorReading r1, SensorReading r2) {
      return r1.value() > r2.value() ? r2 : r1;
  }
}

private static class MyProcessWindowFunction
    extends ProcessWindowFunction<SensorReading, Tuple2<Long, SensorReading>, String, TimeWindow> {

  public void process(String key,
                    Context context,
                    Iterable<SensorReading> minReadings,
                    Collector<Tuple2<Long, SensorReading>> out) {
      SensorReading min = minReadings.iterator().next();
      out.collect(new Tuple2<Long, SensorReading>(context.window().getStart(), min));
  }
}
```

下例展示了如何将 AggregateFunction 与 ProcessWindowFunction 组合，计算平均值并与窗口对应的 key 一同输出。

```java
DataStream<Tuple2<String, Long>> input = ...;

input
  .keyBy(<key selector>)
  .window(<window assigner>)
  .aggregate(new AverageAggregate(), new MyProcessWindowFunction());

// Function definitions

/**
 * The accumulator is used to keep a running sum and a count. The {@code getResult} method
 * computes the average.
 */
private static class AverageAggregate
    implements AggregateFunction<Tuple2<String, Long>, Tuple2<Long, Long>, Double> {
  @Override
  public Tuple2<Long, Long> createAccumulator() {
    return new Tuple2<>(0L, 0L);
  }

  @Override
  public Tuple2<Long, Long> add(Tuple2<String, Long> value, Tuple2<Long, Long> accumulator) {
    return new Tuple2<>(accumulator.f0 + value.f1, accumulator.f1 + 1L);
  }

  @Override
  public Double getResult(Tuple2<Long, Long> accumulator) {
    return ((double) accumulator.f0) / accumulator.f1;
  }

  @Override
  public Tuple2<Long, Long> merge(Tuple2<Long, Long> a, Tuple2<Long, Long> b) {
    return new Tuple2<>(a.f0 + b.f0, a.f1 + b.f1);
  }
}

private static class MyProcessWindowFunction
    extends ProcessWindowFunction<Double, Tuple2<String, Double>, String, TimeWindow> {

  public void process(String key,
                    Context context,
                    Iterable<Double> averages,
                    Collector<Tuple2<String, Double>> out) {
      Double average = averages.iterator().next();
      out.collect(new Tuple2<>(key, average));
  }
}
```

---

## 高级技巧：Consecutive windowed operations

窗口操作的结果会变回 DataStream，并且窗口操作的信息不会保存在输出的元素中。所以，如果你想要保留窗口的 meta-information，需要在 ProcessWindowFunction 里手动将它们放入输出的元素中。

输出元素中保留的唯一相关的信息是元素的 timestamp。它被设置为窗口能允许的最大 timestamp，也就是 end timestamp - 1，因为窗口末端的 timestamp 是排他的。这个情况同时适用于 event-time 窗口和 processing-time 窗口。也就是说，在窗口操作之后，元素总是会携带一个 event-time 或 processing-time timestamp。

对 Processing-time 窗口来说，这并不意味着什么。而对于 event-time 窗口来说，“输出携带 timestamp”以及“watermark 与窗口的相互作用”这两者使建立窗口大小相同的连续窗口操作（consecutive windowed operations）变为可能。

我们先看看 watermark 与窗口的相互作用，然后再来讨论它。

!!! note "Interaction of watermarks and windows"

    当 watermark 到达窗口算子时，它触发了两件事：

    - 这个 watermark 触发了所有最大 timestamp（即 end-timestamp - 1）小于它的窗口
    - 这个 watermark 被原封不动地转发给下游的任务

    通俗来讲，watermark 将当前算子中那些「一旦这个 watermark 被下游任务接收就肯定会就超时」的窗口全部冲走。

**Consecutive windowed operations**

如之前提到的，窗口结果的 timestamp 如何计算以及 watermark 如何与窗口相互作用使串联多个窗口操作成为可能。这提供了一种便利的方法，让你能够有两个连续的窗口，他们既能使用不同的 key，又能让上游操作中某个窗口的数据出现在下游操作的相同窗口。参考下例：

```java
DataStream<Integer> input = ...;

DataStream<Integer> resultsPerKey = input
    .keyBy(<key selector>)
    .window(TumblingEventTimeWindows.of(Time.seconds(5)))
    .reduce(new Summer());

DataStream<Integer> globalResults = resultsPerKey
    .windowAll(TumblingEventTimeWindows.of(Time.seconds(5)))
    .process(new TopKWindowFunction());
```

这个例子中，第一个操作中时间窗口 `[0, 5)` 的结果会出现在下一个窗口操作的 `[0, 5)` 窗口中。这就可以让我们先在一个窗口内按 key 求和，再在下一个操作中找出这个窗口中 top-k 的元素。

---

## 窗口触发器（Triggers）

Trigger 决定了一个窗口（由 window assigner 定义）何时可以被 window function 处理。

每个 WindowAssigner 都有一个默认的 Trigger。如果默认 trigger 无法满足你的需要，你可以在 trigger(...) 调用中指定自定义的 trigger。

Trigger 接口提供了五个方法来响应不同的事件：

- `onElement()` 方法在每个元素被加入窗口时调用。
- `onEventTime()` 方法在注册的 event-time timer 触发时调用。
- `onProcessingTime()` 方法在注册的 event-time timer 触发时调用。
- `onMerge()` 方法与有状态的 trigger 相关。该方法会在两个窗口合并时，将窗口对应 trigger 的状态进行合并，比如使用会话窗口时。
- `clear()` 方法处理在对应窗口被移除时所需的逻辑。

有两点需要注意：

前三个方法通过返回 TriggerResult 来决定 trigger 如何应对到达窗口的事件。应对方案有以下几种：

- `CONTINUE`: 什么也不做
- `FIRE`: 触发计算
- `PURGE`: 清空窗口内的元素
- `FIRE_AND_PURGE`: 触发计算，计算结束后清空窗口内的元素

上面的任意方法都可以用来注册 processing-time 或 event-time timer。

---

## Evictors

Flink 的窗口模型允许在 WindowAssigner 和 Trigger 之外指定可选的 Evictor。可以通过 evictor(...) 方法传入 Evictor。Evictor 可以在 trigger 触发后、调用窗口函数之前或之后从窗口中删除元素。Evictor 接口提供了两个方法实现此功能：

```java
/**
 * Optionally evicts elements. Called before windowing function.
 *
 * @param elements The elements currently in the pane.
 * @param size The current number of elements in the pane.
 * @param window The {@link Window}
 * @param evictorContext The context for the Evictor
 */
void evictBefore(Iterable<TimestampedValue<T>> elements, int size, W window, EvictorContext evictorContext);

/**
 * Optionally evicts elements. Called after windowing function.
 *
 * @param elements The elements currently in the pane.
 * @param size The current number of elements in the pane.
 * @param window The {@link Window}
 * @param evictorContext The context for the Evictor
 */
void evictAfter(Iterable<TimestampedValue<T>> elements, int size, W window, EvictorContext evictorContext);
```

`evictBefore()` 包含在调用窗口函数前的逻辑，而 `evictAfter()` 包含在窗口函数调用之后的逻辑。在调用窗口函数之前被移除的元素不会被窗口函数计算。

Flink 内置有三个 evictor：

- CountEvictor: 仅记录用户指定数量的元素，一旦窗口中的元素超过这个数量，多余的元素会从窗口缓存的开头移除。
- DeltaEvictor: 接收 DeltaFunction 和 threshold 参数，计算最后一个元素与窗口缓存中所有元素的差值，并移除差值大于或等于 threshold 的元素。
- TimeEvictor: 接收 interval 参数，以毫秒表示。它会找到窗口中元素的最大 timestamp max_ts 并移除比 max_ts - interval 小的所有元素。

默认情况下，所有内置的 evictor 逻辑都在调用窗口函数前执行。

!!! note

    指定一个 evictor 可以避免预聚合，因为窗口中的所有元素在计算前都必须经过 evictor。

---

## 关于状态大小的考量

窗口可以被定义在很长的时间段上（比如几天、几周或几个月），并且积累下很大的状态。

当估算窗口计算的储存需求时，可铭记以下几条规则：

- Flink 会为一个元素在其所属的每一个窗口中都创建一个副本。因此，在滚动窗口设置中，一个元素通常只会存在一个副本（一个元素仅属于一个窗口，除非它迟到了）。与之相反，一个元素可能会被拷贝到多个滑动窗口中，正如在 Window Assigners 中所描述的那样。所以，设置一个大小为一天、滑动距离为一秒的滑动窗口可能并非一个好主意。

- ReduceFunction 和 AggregateFunction 能够极大地减少储存需求，因为它们会就地聚合到达的元素，且每个窗口仅储存一个值。而使用 ProcessWindowFunction 则需要累积窗口中所有的元素。

- 使用 Evictor 可以避免预聚合，因为窗口中的所有数据必须先经过 evictor 才能进行计算。

---

## 从旁路输出（side output）获取迟到数据

通过 Flink 的旁路输出功能，你可以获得迟到数据的数据流。

首先，你需要在开窗后的 stream 上使用 `sideOutputLateData(OutputTag)` 表明你需要获取迟到数据。然后，你就可以从窗口操作的结果中获取旁路输出流了。

```java
final OutputTag<T> lateOutputTag = new OutputTag<T>("late-data"){};

DataStream<T> input = ...;

SingleOutputStreamOperator<T> result = input
    .keyBy(<key selector>)
    .window(<window assigner>)
    .allowedLateness(<time>)
    .sideOutputLateData(lateOutputTag)
    .<windowed transformation>(<window function>);

DataStream<T> lateStream = result.getSideOutput(lateOutputTag);
```

---

## 迟到数据的处理

所谓的「迟到数据」，是指某个水位线之后到来的数据，但它的时间戳其实是在水位线之前的。**只有在事件时间语义下，讨论迟到数据的处理才是有意义的**。

**处理迟到数据的方法：**

- ^^对于乱序流，水位线可以设置一个延迟时间^^

: 水位线其实是所有事件时间定时器触发的判断标准。**水位线的延迟，相当于全局时钟的滞后**。一般情况不应该把水位线的延迟设置得太大，否则流处理的实时性就会大大降低。

- ^^做窗口计算时，我们可以设置窗口的允许延迟时间^^

: 由于大部分乱序数据可以被水位线的延迟等到，所以往往迟到的数据不会太多。这样，我们会在水位线到达窗口结束时间时，先快速地输出一个近似正确的计算结果，然后**保持窗口继续等到延迟数据**，每来一条数据，窗口就会再次计算，并将更新后的结果输出。这样就可以逐步修正计算结果，最终得到准确的统计值了。

- ^^窗口可以将迟到数据输出到测输出流^^

: 用窗口的侧输出流来收集关窗以后的迟到数据。这种方式是**最后兜底的方法**，只能保证数据不丢失。因为窗口已经真正关闭，所以是无法基于之前窗口的结果直接做更新的。我们只能将之前的窗口计算结果保存下来，然后获取侧输出流中的迟到数据，判断数据所属的窗口，手动对结果进行合并更新。
