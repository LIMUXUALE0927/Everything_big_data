# 状态管理

## 有状态算子

在 Flink 中，算子任务可以分为无状态和有状态两种情况。

无状态的算子任务只需要观察每个独立事件，根据当前输入的数据直接转换输出结果。一些基本转换算子，如 map、filter、flatMap，计算时不依赖其他数据，就都属于无状态的算子。

而有状态的算子任务，则除当前数据之外，还需要一些其他数据来得到计算结果。这里的“其他数据”，就是所谓的状态（state），最常见的就是之前到达的数据，或者由之前数据计算出的某个结果。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410040421724.png)

有状态算子的一般处理流程：

1. 算子任务接收到上游发来的数据
2. 获取当前状态
3. 根据业务逻辑进行计算，更新状态
4. 得到计算结果，输出发送到下游任务

---

## 状态的管理

在传统的事务型处理架构中，这种额外的状态数据是保存在数据库中的。而对于实时流处理来说，这样做需要频繁读写外部数据库，如果数据规模非常大肯定就达不到性能要求了。所以 Flink 的解决方案是，**将状态直接保存在内存中来保证性能，并通过分布式扩展来提高吞吐量**。

但是在分布式的场景下，还需要额外考虑：

1. **容错性**，也就是故障后的恢复。状态只保存在内存中显然是不够稳定的，我们需要将它持久化保存，在发生故障后可以从这个备份中恢复状态
2. 分布式应用的**横向扩展性**。当处理的数据量增大时，我们应该相应地对计算资源扩容，调大并行度，此时就涉及到了状态的重组调整

---

## 状态的分类

### 托管状态和原始状态

Flink 的状态有两种：**托管状态（Managed State）**和**原始状态（Raw State）**。

托管状态就是由 Flink 统一管理的，状态的存储访问、故障恢复和重组等一系列问题都由 Flink 实现，我们只要调接口就可以。而原始状态则是自定义的，相当于就是开辟了一块内存，需要我们自己管理，实现状态的序列化和故障恢复。

托管状态是由 Flink 的运行时（Runtime）来托管的。在配置容错机制后，状态会自动持久化保存，并在发生故障时自动恢复。当应用发生横向扩展时，状态也会自动地重组分配到所有的子任务实例上。Flink 提供了**值状态（ValueState）、列表状态（ListState）、映射状态（MapState）、聚合状态（AggregateState）**等多种结构，内部支持各种数据类型。聚合、窗口等算子中内置的状态，就都是托管状态。我们也可以在富函数类（RichFunction）中通过上下文来自定义状态，这些也都是托管状态。

原始状态就全部需要自定义了。Flink 不会对状态进行任何自动操作，也不知道状态的具体数据类型，只会把它当作最原始的**字节（Byte）数组**来存储。

---

### 算子状态和按键分区状态

Flink 中的托管状态可以分为两类：**算子状态**和**按键分区状态**。

^^算子状态^^

: 状态作用范围限定为当前的算子任务实例，也就是只对当前并行子任务实例有效。这就意味着对于一个并行子任务，占据了一个“分区”，它所处理的所有数据都会访问到相同的状态，状态对于同一任务而言是共享的。

: ![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410040430561.png)

^^按键分区状态^^

: 按键分区状态是根据输入流中定义的键（key）来维护和访问的，所以只能定义在按键分区流（KeyedStream）中，也就 keyBy 之后才可以使用。

: ![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410040431803.png)

**按键分区状态的数据结构：**

- ValueState：即类型为 T 的单值状态。这个状态与对应的 key 绑定，是最简单的状态了。它可以通过 `update()` 更新状态值，通过 `value()` 获取状态值。
- ListState：即 key 上的状态值为一个列表。可以通过 `add()` 往列表中附加值；也可以通过 `get()` 返回一个 Iterable 来遍历状态值。
- ReducingState：这种状态通过用户传入的 reduceFunction，每次调用 `add()` 添加值的时候，会调用 reduceFunction，最后合并到一个单一的状态值。
- MapState：即状态值为一个 map。用户通过 `put()` 或 `putAll()` 添加元素。

---

### 状态持久化和状态后端

在 Flink 的状态管理机制中，很重要的一个功能就是对状态进行**持久化**保存，这样就可以在发生故障后进行重启恢复。Flink 对状态进行持久化的方式，就是将当前所有分布式状态进行「快照」保存，写入一个「检查点」（checkpoint）或者「保存点」（savepoint）保存到外部存储系统中。

**状态持久化:**

Flink 会定期保存检查点，在检查点中会记录每个算子的 id 和状态。如果发生故障，Flink 就会用最近一次成功保存的检查点来恢复应用的状态，重新启动处理流程，就如同“读档”一样。

**状态后端：**

检查点的保存离不开 JobManager 和 TaskManager，以及外部存储系统的协调。在应用进行检查点保存时，首先会由 JobManager 向所有 TaskManager 发出触发检查点的命令；TaskManger 收到之后，将当前任务的所有状态进行快照保存，持久化到远程的存储介质中；完成之后向 JobManager 返回确认信息。这个过程是分布式的，当 JobManger 收到所有 TaskManager 的返回信息后，就会确认当前检查点成功保存，如图 9-5 所示。而这一切工作的协调，就需要一个“专职人员”来完成。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410040440542.png)

在 Flink 中，状态的存储、访问以及维护，都是由一个可插拔的组件决定的，这个组件就叫作**状态后端（state backend）**。状态后端主要负责两件事：一是**本地的状态管理**，二是**将检查点（checkpoint）写入远程的持久化存储**。

Flink 中提供了两类不同的状态后端，一种是**“哈希表状态后端”（HashMapStateBackend）**，另一种是**“内嵌 RocksDB 状态后端”（EmbeddedRocksDBStateBackend）**。如果没有特别配置，系统默认的状态后端是 HashMapStateBackend。

---

## 使用状态

### Key Selector

如果你希望使用 keyed state，首先需要为 DataStream 指定 key（主键）。这个主键用于状态分区（也会给数据流中的记录本身分区）。 你可以使用 DataStream 中 Java/Scala API 的 `keyBy(KeySelector)` 来指定 key。

```java
// some ordinary POJO
public class WC {
  public String word;
  public int count;

  public String getWord() { return word; }
}
DataStream<WC> words = // [...]
KeyedStream<WC> keyed = words
  .keyBy(WC::getWord);
```

### 使用 Keyed State

keyed state 接口提供不同类型状态的访问接口，这些状态都作用于当前输入数据的 key 下。换句话说，这些状态仅可在 KeyedStream 上使用。

- ValueState：即类型为 T 的单值状态。这个状态与对应的 key 绑定，是最简单的状态了。它可以通过 update 方法更新状态值，通过 value 方法获取状态值。
- ListState：即 key 上的状态值为一个列表。可以通过 add 方法往列表中附加值；也可以通过 get 方法返回一个 Iterable 来遍历状态值。
- ReducingState:这种状态通过用户传入的 reduceFunction，每次调用 add 方法添加值的时候，会调用 reduceFunction，最后合并到一个单一的状态值。
- AggregatingState<IN, OUT\>：保留一个单值，表示添加到状态的所有值的聚合。和 ReducingState 相反的是, 聚合类型可能与添加到状态的元素的类型不同。 接口与 ListState 类似，但使用 add(IN) 添加的元素会用指定的 AggregateFunction 进行聚合。
- MapState<UK, UV\>：即状态值为一个 map。用户通过 put 或 putAll 方法添加元素。使用 get(UK) 检索特定 key。 使用 entries()，keys() 和 values() 分别检索映射、键和值的可迭代视图。

需要注意的是，以上所述的 State 对象，仅仅用于与状态进行交互（更新、删除、清空等），而真正的状态值，有可能是存在内存、磁盘、或者其他分布式存储系统中。相当于我们只是持有了这个状态的句柄。

你必须创建一个 StateDescriptor，才能得到对应的状态句柄。 这保存了状态名称（正如我们稍后将看到的，你可以创建多个状态，并且它们必须具有唯一的名称以便可以引用它们）， 状态所持有值的类型，并且可能包含用户指定的函数，例如 ReduceFunction。 根据不同的状态类型，可以创建 ValueStateDescriptor，ListStateDescriptor， AggregatingStateDescriptor, ReducingStateDescriptor 或 MapStateDescriptor。

状态通过 RuntimeContext 进行访问，因此只能在 rich functions 中使用。RichFunction 中 RuntimeContext 提供如下方法：

```java
ValueState<T> getState(ValueStateDescriptor<T>)
ReducingState<T> getReducingState(ReducingStateDescriptor<T>)
ListState<T> getListState(ListStateDescriptor<T>)
AggregatingState<IN, OUT> getAggregatingState(AggregatingStateDescriptor<IN, ACC, OUT>)
MapState<UK, UV> getMapState(MapStateDescriptor<UK, UV>)
```

下面是一个 FlatMapFunction 的例子，展示了如何将这些部分组合起来：

```java
public class CountWindowAverage extends RichFlatMapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>> {

    /**
     * The ValueState handle. The first field is the count, the second field a running sum.
     */
    private transient ValueState<Tuple2<Long, Long>> sum;

    @Override
    public void flatMap(Tuple2<Long, Long> input, Collector<Tuple2<Long, Long>> out) throws Exception {

        // access the state value
        Tuple2<Long, Long> currentSum = sum.value();

        // update the count
        currentSum.f0 += 1;

        // add the second field of the input value
        currentSum.f1 += input.f1;

        // update the state
        sum.update(currentSum);

        // if the count reaches 2, emit the average and clear the state
        if (currentSum.f0 >= 2) {
            out.collect(new Tuple2<>(input.f0, currentSum.f1 / currentSum.f0));
            sum.clear();
        }
    }

    @Override
    public void open(Configuration config) {
        ValueStateDescriptor<Tuple2<Long, Long>> descriptor =
                new ValueStateDescriptor<>(
                        "average", // the state name
                        TypeInformation.of(new TypeHint<Tuple2<Long, Long>>() {}), // type information
                        Tuple2.of(0L, 0L)); // default value of the state, if nothing was set
        sum = getRuntimeContext().getState(descriptor);
    }
}

// this can be used in a streaming program like this (assuming we have a StreamExecutionEnvironment env)
env.fromElements(Tuple2.of(1L, 3L), Tuple2.of(1L, 5L), Tuple2.of(1L, 7L), Tuple2.of(1L, 4L), Tuple2.of(1L, 2L))
        .keyBy(value -> value.f0)
        .flatMap(new CountWindowAverage())
        .print();

// the printed output will be (1,4) and (1,5)
```

这个例子实现了一个简单的计数窗口。 我们把元组的第一个元素当作 key（在示例中都 key 都是 “1”）。 该函数将出现的次数以及总和存储在 “ValueState” 中。 一旦出现次数达到 2，则将平均值发送到下游，并清除状态重新开始。 请注意，我们会为每个不同的 key（元组中第一个元素）保存一个单独的值。

---

### Operator State

算子状态（或者非 keyed 状态）是绑定到一个并行算子实例的状态。Kafka Connector 是 Flink 中使用算子状态一个很具有启发性的例子。Kafka consumer 每个并行实例维护了 topic partitions 和偏移量的 map 作为它的算子状态。

当并行度改变的时候，算子状态支持将状态重新分发给各并行算子实例。处理重分发过程有多种不同的方案。

在典型的有状态 Flink 应用中你无需使用算子状态。它大都作为一种特殊类型的状态使用。用于实现 source/sink，以及无法对 state 进行分区而没有主键的这类场景中。

---

### Broadcast State

广播状态是一种特殊的算子状态。引入它的目的在于支持一个流中的元素需要广播到所有下游任务的使用情形。在这些任务中广播状态用于保持所有子任务状态相同。该状态接下来可在第二个处理记录的数据流中访问。可以设想包含了一系列用于处理其他流中元素规则的低吞吐量数据流，这个例子自然而然地运用了广播状态。考虑到上述这类使用情形，广播状态和其他算子状态的不同之处在于：

- 它具有 map 格式
- 它仅在一些特殊的算子中可用。这些算子的输入为一个广播数据流和非广播数据流
- 这类算子可以拥有不同命名的多个广播状态

---

### 使用 Broadcast State

在这里我们使用一个例子来展现 broadcast state 提供的接口。假设存在一个序列，序列中的元素是具有不同颜色与形状的图形，我们希望在序列里相同颜色的图形中寻找满足一定顺序模式的图形对（比如在红色的图形里，有一个长方形跟着一个三角形）。 同时，我们希望寻找的模式也会随着时间而改变。

在这个例子中，我们定义两个流，一个流包含图形（Item），具有颜色和形状两个属性。另一个流包含特定的规则（Rule），代表希望寻找的模式。

在图形流中，我们需要首先使用颜色将流进行进行分区（keyBy），这能确保相同颜色的图形会流转到相同的物理机上。

```java
// 将图形使用颜色进行划分
KeyedStream<Item, Color> colorPartitionedStream = itemStream
                        .keyBy(new KeySelector<Item, Color>(){...});
```

对于规则流，它应该被广播到所有的下游 task 中，下游 task 应当存储这些规则并根据它寻找满足规则的图形对。下面这段代码会完成：

1. 将规则广播给所有下游 task
2. 使用 MapStateDescriptor 来描述并创建 broadcast state 在下游的存储结构

```java
// 一个 map descriptor，它描述了用于存储规则名称与规则本身的 map 存储结构
MapStateDescriptor<String, Rule> ruleStateDescriptor = new MapStateDescriptor<>(
			"RulesBroadcastState",
			BasicTypeInfo.STRING_TYPE_INFO,
			TypeInformation.of(new TypeHint<Rule>() {}));

// 广播流，广播规则并且创建 broadcast state
BroadcastStream<Rule> ruleBroadcastStream = ruleStream
                        .broadcast(ruleStateDescriptor);
```

为了关联一个非广播流（keyed 或者 non-keyed）与一个广播流（BroadcastStream），我们可以通过非广播流调用 `connect()` 方法，并将 BroadcastStream 当做参数传入。 这个方法的返回参数是 BroadcastConnectedStream，具有类型方法 `process()`，传入一个特殊的 CoProcessFunction 来书写我们的模式识别逻辑。 具体传入 `process()` 的是哪个类型取决于非广播流的类型：

- 如果流是一个 keyed 流，那就是 KeyedBroadcastProcessFunction 类型
- 如果流是一个 non-keyed 流，那就是 BroadcastProcessFunction 类型。

在我们的例子中，图形流是一个 keyed stream，所以我们书写的代码如下：

```java
DataStream<String> output = colorPartitionedStream
                 .connect(ruleBroadcastStream)
                 .process(

                     // KeyedBroadcastProcessFunction 中的类型参数表示：
                     //   1. key stream 中的 key 类型
                     //   2. 非广播流中的元素类型
                     //   3. 广播流中的元素类型
                     //   4. 结果的类型，在这里是 string

                     new KeyedBroadcastProcessFunction<Color, Item, Rule, String>() {
                         // 模式匹配逻辑
                     }
                 );
```

更多关于 Broadcast State 的信息可以在 [Broadcast State](https://nightlies.apache.org/flink/flink-docs-release-1.20/zh/docs/dev/datastream/fault-tolerance/broadcast_state/) 中找到。
