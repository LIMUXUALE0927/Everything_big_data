# 容错机制

为了使状态具备容错能力，Flink 需要对状态进行检查点（checkpoint）。检查点使 Flink 能够恢复状态和流中的位置，从而为应用程序提供与无故障（failure-free）执行相同的语义。

## 术语解释

**Snapshot**
: Flink 作业状态全局一致镜像的通用术语。快照包括指向每个数据源的指针（例如，到文件或 Kafka 分区的偏移量）以及每个作业的有状态运算符的状态副本，该状态副本是处理了 sources 偏移位置之前所有的事件后而生成的状态。

**Checkpoint**
: 一种由 Flink 自动执行的快照，其目的是能够从故障中恢复，为应用程序提供与无故障（failure-free）执行相同的语义。Checkpoint 可以是增量的，并为快速恢复进行了优化。

**Savepoint**
: 用户出于某种操作目的（例如有状态的重新部署/升级/缩放操作）手动（或 API 调用）触发的快照。Savepoint 始终是完整的，并且已针对操作灵活性进行了优化。

## Checkpoint

检查点是 Flink 容错机制的核心。在 Flink 中，检查点的保存是**周期性触发**的，间隔时间可以进行设置。所以检查点作为应用状态的一份“存档”，其实就是所有任务状态在同一时间点的一个「快照」（snapshot），它的触发是周期性的。

在 Flink 中，检查点保存的时间点是**当所有任务都恰好处理完一个相同的输入数据的时候**，将它们的状态保存下来。首先，这样避免了除状态之外其他额外信息的存储，提高了检查点保存的效率。其次，一个数据要么就是被所有任务完整地处理完，状态得到了保存；要么就是没处理完，状态全部没保存：这就相当于构建了一个「事务」（transaction）。

不过不同的任务怎么知道处理的是“同一个”数据呢？Flink 借鉴水位线（watermark）的设计，**在数据流中插入一个特殊的数据结构 Checkpoint Barrier，专门用来表示触发检查点保存的时间点**。

Checkpoint Barrier 由 Source 算子注入到常规的数据流中，它的位置是限定好的，不能超过其他数据，也不能被后面的数据超过。检查点分界线中带有一个检查点 ID，这是当前要保存的检查点的唯一标识。这样，分界线就将一条流逻辑上分成了两部分：分界线之前到来的数据导致的状态更改，都会被包含在当前分界线所表示的检查点中；而基于分界线之后的数据导致的状态更改，则会被包含在之后的检查点中。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041042954.png)

在 JobManager 中有一个**「检查点协调器」（checkpoint coordinator）**，专门用来协调处理检查点的相关工作。检查点协调器会定期向 TaskManager 发出指令，要求保存检查点（带着检查点 ID）；TaskManager 会让所有的 Source 任务把自己的偏移量（算子状态）保存起来，并将带有检查点 ID 的分界线（barrier）插入到当前的数据流中，然后像正常的数据一样像下游传递；之后 Source 任务就可以继续读入新的数据了。

由于来自不同快照的多个 Checkpoint Barrier 可以同时存在于流中，这意味着各种快照可能会并发发生。因此 Flink 使用了 Chandy-Lamport 算法的一种变体，被称为**「异步分界线快照」（asynchronous barrier snapshotting）**算法。算法的核心就是两个原则：

1. 当上游任务向多个并行下游任务发送 barrier 时，需要**广播**出去
2. 而当多个上游任务向同一个下游任务传递 barrier 时，需要在下游任务执行**「分界线对齐」（barrier alignment）**操作，也就是需要等到所有并行分区的 barrier 都到齐，才可以开始状态的保存

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041052754.png)

^^分界线对齐：^^

- 一旦算子从一个输入流接收到快照 barrier n，它在接收到来自其他输入的 barrier n 之前，**不能处理该流的任何后续数据，而是会缓存起来**。否则，它将混合属于快照 n 的记录与属于快照 n+1 的记录。
- 当算子收到所有分区的 barrier n 时，就可以对当前状态做快照，保存到持久化存储中。存储完成之后，同样将 barrier n 向下游继续传递，并通知 JobManager 保存完毕。
- 完成检查点保存之后，任务就可以继续正常处理数据了。这时如果有等待分界线对齐时缓存的数据，需要先做处理，然后再按照顺序依次处理新到的数据。

---

## Checkpoint 算法流程

^^STEP 1：JobManager 发送指令，触发检查点的保存；Source 任务保存状态，插入分界线^^

JobManager 会周期性地向每个 TaskManager 发送一条带有新检查点 ID 的消息，通过这种方式来启动检查点。收到指令后，TaskManger 会在所有 Source 任务中插入一个分界线（barrier），并将偏移量保存到远程的持久化存储中。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041146188.png)

^^STEP 2：状态快照保存完成，分界线向下游传递^^

状态存入持久化存储之后，会返回通知给 Source 任务；Source 任务就会向 JobManager 确认检查点完成，然后像数据一样把 barrier 向下游任务传递。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041147319.png)

^^STEP 3：向下游多个并行子任务广播分界线，执行分界线对齐^^

Map 任务没有状态，所以直接将 barrier 继续向下游传递。这时由于进行了 keyBy 分区，所以需要将 barrier 广播到下游并行的两个 Sum 任务。同时，Sum 任务可能收到来自上游两个并行 Map 任务的 barrier，所以需要执行「**分界线对齐**」操作。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041148553.png)

^^STEP 4：分界线对齐后，保存状态到持久化存储^^

各个分区的分界线都对齐后，就可以对当前状态做快照，保存到持久化存储了。存储完成之后，同样将 barrier 向下游继续传递，并通知 JobManager 保存完毕。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041149584.png)

^^STEP 5：先处理缓存数据，然后正常继续处理^^

完成检查点保存之后，任务就可以继续正常处理数据了。这时如果有等待分界线对齐时缓存的数据，需要先做处理；然后再按照顺序依次处理新到的数据。

当 JobManager 收到所有任务成功保存状态的信息，就可以确认当前检查点成功保存。之后遇到故障就可以从这里恢复了。

!!! info "不对齐的检查点保存"

    由于分界线对齐要求先到达的分区做缓存等待，一定程度上会影响处理的速度，当出现背压（backpressure）时，下游任务会堆积大量的缓冲数据，检查点可能需要很久才可以保存完毕。为了应对这种场景，Flink 1.11 之后提供了**不对齐的检查点保存**方式，可以将未处理的缓冲数据（in-flight data）也保存进检查点。这样，当我们遇到一个分区 barrier 时就不需等待对齐，而是可以直接启动状态的保存了。

---

## 持久化存储

由 Flink 管理的 keyed state 是一种分片的键/值存储，每个 keyed state 的工作副本都保存在负责该键的 TaskManager 本地中。另外，Operator state 也保存在机器节点本地。Flink 定期获取所有状态的快照，并将这些快照复制到持久化的位置，例如分布式文件系统。

如果发生故障，Flink 可以恢复应用程序的完整状态并继续处理，就如同没有出现过异常。

Flink 管理的状态存储在 state backend 中。Flink 有两种 state backend 的实现：一种基于 RocksDB 内嵌 key/value 存储将其工作状态保存在磁盘上的，另一种基于堆的 state backend，将其工作状态保存在 Java 的堆内存中。这种基于堆的 state backend 有两种类型：FsStateBackend，将其状态快照持久化到分布式文件系统；MemoryStateBackend，它使用 JobManager 的堆保存状态快照。

| 名称                | Working State      | 状态备份            | 快照        | 适用场景                                                 |
| ------------------- | ------------------ | ------------------- | ----------- | -------------------------------------------------------- |
| MemoryStateBackend  | JVM Heap           | JobManager JVM Heap | 全量        | 适用于小状态（本地）的测试和实验                         |
| FsStateBackend      | JVM Heap           | 分布式文件系统      | 全量        | 快速，需要大的堆内存。受限制于 GC                        |
| RocksDBStateBackend | 本地磁盘 (tmp dir) | 分布式文件系统      | 全量 / 增量 | 支持大于内存大小的状态。经验法则：比基于堆的后端慢 10 倍 |

对于保存在 RocksDBStateBackend 中的对象，访问和更新涉及**序列化和反序列化**，所以会有更大的开销。但 RocksDB 的状态量仅受本地磁盘大小的限制。还要注意，只有 RocksDBStateBackend 能够进行增量快照，这对于具有大量变化缓慢状态的应用程序来说是大有裨益的。

所有这些 state backends 都能够异步执行快照，这意味着它们可以在不妨碍正在进行的流处理的情况下执行快照。

---

## 一致性语义

Flink 中的一致性其实就是结果的正确性。对于 Flink 来说，多个节点并行处理不同的任务，**我们要保证计算结果是正确的，就必须不漏掉任何一个数据，而且也不会重复处理同一个数据**。流式计算本身就是一个一个来的，所以正常处理的过程中结果肯定是正确的，但在发生故障、需要恢复状态进行回滚时就需要更多的保障机制了。我们通过检查点的保存来保证状态恢复后结果的正确，所以主要讨论的就是「**状态的一致性**」。

一般说来，状态一致性有三种级别：

^^最多一次（AT-MOST-ONCE）^^

: 当任务发生故障时，最简单的做法就是直接重启，别的什么都不干；既不恢复丢失的状态，也不重放丢失的数据。每个数据在正常情况下会被处理一次，遇到故障时就会丢掉，所以就是“最多处理一次”。这种情况数据会直接被丢掉，即没有任何操作来保证结果的准确性。所以这种类型的保证也叫“没有保证”。

^^至少一次（AT-LEAST-ONCE）^^

: 在实际应用中，我们一般会希望至少不要丢掉数据。这种一致性级别就叫作「**至少一次**」（at-least-once），就是说是所有数据都不会丢，肯定被处理了，不过不能保证只处理一次，有些数据会被**重复处理**。

: 在有些场景下，重复处理数据是不影响结果的正确性的，这种操作具有“幂等性”。比如，如果我们统计 UV，需要对每个用户的访问数据进行去重处理，所以即使同一个数据被处理多次，也不会影响最终的结果。

: **为了保证达到 at-least-once 的状态一致性，我们需要在发生故障时能够重放数据**。最常见的做法是，可以用持久化的事件日志系统，把所有的事件写入到持久化存储中。这时只要记录一个偏移量，当任务发生故障重启后，**重置偏移量**就可以重放检查点之后的数据了。

^^精确一次（EXACTLY-ONCE）^^

: 最严格的一致性保证，就是所谓的「**精确一次**」（exactly-once）。这也是最难实现的状态一致性语义。exactly-once 意味着所有数据不仅不会丢失，而且只被处理一次，不会重复处理。也就是说对于每一个数据，最终体现在状态和输出结果上，只能有一次统计。exactly-once 可以真正意义上保证结果的绝对正确，在发生故障恢复后，就好像从未发生过故障一样。

: 要做到 exactly-once，首先必须能达到 at-least-once 的要求，就是数据不丢。所以同样需要有**数据重放机制**来保证这一点。另外，还需要有专门的设计保证每个数据只被处理一次。Flink 中使用的是一种轻量级快照机制**检查点（checkpoint）**来保证 exactly-once 语义。

---

### 端到端精确一次

为了实现端到端的精确一次，以便 sources 中的每个事件都仅精确一次对 sinks 生效，必须满足以下条件：

- 你的 sources 必须是可重放的，并且
- 你的 sinks 必须是事务性的（或幂等的）

^^输入端^^

: 想要在故障恢复后不丢数据，外部数据源就必须拥有**重放数据**的能力。常见的做法就是**对数据进行持久化保存，并且可以重设数据的读取位置**。一个最经典的应用就是 Kafka。在 Flink 的 Source 任务中将数据读取的偏移量保存为状态，这样就可以在故障恢复时从检查点中读取出来，对数据源重置偏移量，重新获取数据。

^^Flink 应用端^^

: Flink 通过 Checkpoint 机制，把状态存盘，发生故障的时候可以恢复，保证内部的状态一致性。

^^输出端^^

: Sink 端是最复杂的，因为数据是落地到其他系统上的，数据一旦离开 Flink 之后，Flink 就监控不到这些数据了，所以精准一次处理语义必须也要应用于 Flink 写入数据的外部系统，故这些外部系统必须提供一种手段允许提交或回滚这些写入操作，同时还要保证与 Flink Checkpoint 能够协调使用（Kafka 0.11 版本已经实现精确一次处理语义）。

: **若要 Sink 支持精准一次处理语义(EOS)，它必须以事务的方式写数据到 Kafka**，这样当提交事务时两次 Checkpoint 间的所有写入操作当作为一个事务被提交。这确保了出现故障或崩溃时这些写入操作能够被回滚。

: 当然，在一个分布式且含有多个并发执行 Sink 的应用中，仅仅执行单次提交或回滚是不够的，因为所有组件都必须对这些提交或回滚达成共识，这样才能保证得到一个一致性的结果。Flink 使用**两阶段提交协议**以及预提交(Pre-commit)阶段来解决这个问题。

---

### 两阶段提交（2PC）

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041413410.png)

**两阶段提交协议（Two-Phase Commit，2PC）**是很常用的解决分布式事务问题的方式，它可以保证在分布式事务中，要么所有参与进程都提交事务，要么都取消，即实现 ACID 中的 A （原子性）。

在数据一致性的环境下，其代表的含义是：要么所有备份数据同时更改某个数值，要么都不改，以此来达到数据的强一致性。

两阶段提交协议中有两个重要角色，协调者（Coordinator）和参与者（Participant），其中协调者只有一个，起到分布式事务的协调管理作用，参与者有多个。

顾名思义，两阶段提交将提交过程划分为连续的两个阶段：表决阶段（Voting）和提交阶段（Commit）。

**两阶段提交流程**

^^第一阶段：表决阶段^^

: 协调者向所有参与者发送一个 VOTE_REQUEST 消息。

: 当参与者接收到 VOTE_REQUEST 消息，向协调者发送 VOTE_COMMIT 消息作为回应，告诉协调者自己已经做好准备提交准备，如果参与者没有准备好或遇到其他故障，就返回一个 VOTE_ABORT 消息，告诉协调者目前无法提交事务。

^^第二阶段：提交阶段^^

: 协调者收集来自各个参与者的表决消息。如果所有参与者一致认为可以提交事务，那么协调者决定事务的最终提交，在此情形下协调者向所有参与者发送一个 GLOBAL_COMMIT 消息，通知参与者进行本地提交；如果所有参与者中有任意一个返回消息是 VOTE_ABORT，协调者就会取消事务，向所有参与者广播一条 GLOBAL_ABORT 消息通知所有的参与者取消事务。

: 每个提交了表决信息的参与者等候协调者返回消息，如果参与者接收到一个 GLOBAL_COMMIT 消息，那么参与者提交本地事务，否则如果接收到 GLOBAL_ABORT 消息，则参与者取消本地事务。

---

### Flink & Kafka 数据管道实现精确一次

^^STEP 1：启动检查点保存^^

: 当 Checkpoint 启动时，JobManager 会将检查点分界线（checkpoint barrier）注入数据流，checkpoint barrier 会在算子间传递下去。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041421462.png)

^^STEP 2：算子任务对状态做快照^^

: 分界线（barrier）会在算子间传递下去。每个算子收到 barrier 时，会将当前的状态做个快照，保存到状态后端。

: Source 任务将 barrier 插入数据流后，也会将当前读取数据的偏移量作为状态写入检查点，存入状态后端，然后把 barrier 向下游传递，自己就可以继续读取数据了。接下来 barrier 传递到了内部的 Window 算子，它同样会对自己的状态进行快照保存，写入远程的持久化存储。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041421070.png)

^^STEP 3：Sink 任务开启事务，进行预提交^^

: 分界线（barrier）终于传到了 Sink 任务，这时 Sink 任务会开启一个事务。接下来到来的所有数据，Sink 任务都会通过这个事务来写入 Kafka。这里 barrier 是检查点的分界线，也是事务的分界线。由于之前的检查点可能尚未完成，因此上一个事务也可能尚未提交；此时 barrier 的到来开启了新的事务，上一个事务尽管可能没有被提交，但也不再接收新的数据了。

: 对于 Kafka 而言，提交的数据会被标记为“未确认”（uncommitted）。这个过程就是所谓的“预提交”（pre-commit）。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041426362.png)

^^STEP 4：检查点保存完成，提交事务^^

: 当所有算子的快照都完成，也就是这次的检查点保存最终完成时，JobManager 会向所有任务发确认通知，告诉大家当前检查点已成功保存。

: 当 Sink 任务收到确认通知后，就会正式提交之前的事务，把之前“未确认”的数据标为“已确认” ，接下来就可以正常消费了。

: 在任务运行中的任何阶段失败，都会从上一次的状态恢复，所有没有正式提交的数据也会回滚。这样，Flink 和 Kafka 连接构成的流处理系统，就实现了端到端的 exactly-once 状态一致性。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202410041427370.png)

---

**Flink 端到端精确一次流程总结：**

1. Flink 消费到 Kafka 数据之后，就会开启一个 Kafka 的事务，正常写入 Kafka 分区日志但标记为未提交，这就是 pre-commit
2. 一旦所有的算子完成各自的 pre-commit，它们会发起一个 commit 操作
3. 如果有任意一个 pre-commit 失败，所有其他的 pre-commit 必须停止，并且 Flink 会回滚到最近成功完成的 checkpoint
4. 当所有的算子完成任务时，Sink 端保存当前状态，存入 checkpoint，通知 JobManager，并提交外部事务
5. JobManager 收到所有任务的通知，发出确认信息，表示 checkpoint 已完成，Sink 收到 JobManager 的确认信息，正式 commit 这段时间的数据
6. Kafka 事务执行完毕，提交的数据可以正常消费

---

## Checkpoint 配置

**Checkpoint 的前提条件**

Flink 的 checkpoint 机制会和持久化存储进行交互，读写流与状态。一般需要：

- 一个能够回放一段时间内数据的持久化数据源，例如持久化消息队列（例如 Apache Kafka、RabbitMQ、 Amazon Kinesis、 Google PubSub 等）或文件系统（例如 HDFS、 S3、 GFS、 NFS、 Ceph 等）。
- 存放状态的持久化存储，通常为分布式文件系统（比如 HDFS、 S3、 GFS、 NFS、 Ceph 等）。

默认情况下 checkpoint 是禁用的。通过调用 StreamExecutionEnvironment 的 `enableCheckpointing(n)` 来启用 checkpoint，里面的 n 是进行 checkpoint 的间隔，单位毫秒。

其他配置：

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

// 每 1000ms 开始一次 checkpoint
env.enableCheckpointing(1000);

// 高级选项：

// 设置模式为精确一次 (这是默认值)
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

// 确认 checkpoints 之间的时间会进行 500 ms
env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);

// Checkpoint 必须在一分钟内完成，否则就会被抛弃
env.getCheckpointConfig().setCheckpointTimeout(60000);

// 允许两个连续的 checkpoint 错误
env.getCheckpointConfig().setTolerableCheckpointFailureNumber(2);

// 同一时间只允许一个 checkpoint 进行
env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);

// 使用 externalized checkpoints，这样 checkpoint 在作业取消后仍就会被保留
env.getCheckpointConfig().setExternalizedCheckpointRetention(
        ExternalizedCheckpointRetention.RETAIN_ON_CANCELLATION);

// 开启实验性的 unaligned checkpoints
env.getCheckpointConfig().enableUnalignedCheckpoints();
```
