# HBase

## HBase 简介

HBase 是一款高可靠、易扩展、高性能的分布式 KV 数据库系统。它是一个分布式的、面向列的开源数据库，运行在 HDFS 之上。HBase 是一个适合存储大规模表的数据库，它可以存储海量的数据，支持高并发的随机读写操作。

## HBase 数据模型

> HBase: sparse，distributed，persistent multidimensional sorted map

从逻辑视图来看，HBase 中的数据是以表形式进行组织的，而且和关系型数据库中的表一样，HBase 中的表也由行和列构成，因此 HBase 非常容易理解。

但从物理视图来看，HBase 是一个 Map，由键值（KeyValue，KV）构成，不过与普通的 Map 不同，HBase 是一个稀疏的、分布式的、多维排序的 Map。

### 逻辑视图

在具体了解逻辑视图之前有必要先看看 HBase 中的基本概念：

- table：表，一个表包含多行数据。
- row：行，一行数据包含一个唯一标识 rowkey、多个 column 以及对应的值。在 HBase 中，一张表中所有 row 都按照 rowkey 的字典序由小到大排序。
- column：列，与关系型数据库中的列不同，HBase 中的 column 由 column family（列簇）以及 qualifier（列名）两部分组成，两者中间使用 `:` 相连。比如 contents：html，其中 contents 为列簇，html 为列簇下具体的一列。column family 在表创建的时候需要指定，用户不能随意增减。一个 column family 下可以设置任意多个 qualifier，因此可以理解为 HBase 中的列可以动态增加，理论上甚至可以扩展到上百万列。
- timestamp：时间戳，每个 cell 在写入 HBase 的时候都会默认分配一个时间戳作为该 cell 的版本，当然，用户也可以在写入的时候自带时间戳。HBase 支持多版本特性，即同一 rowkey、column 下可以有多个 value 存在，这些 value 使用 timestamp 作为版本号，版本越大，表示数据越新。
- cell：单元格，由五元组（row，column，timestamp，type，value）组成的结构，其中 type 表示 Put/Delete 这样的操作类型，timestamp 代表这个 cell 的版本。这个结构在数据库中实际是以 KV 结构存储的，其中（row，column，timestamp，type）是 K，value 字段对应 KV 结构的 V。

下图是 BigTable 中一张示例表的逻辑视图，表中主要存储网页信息。示例表中包含两行数据，两个 rowkey 分别为 com.cnn.www
和 com.example.www，按照字典序由小到大排列。每行数据有三个列簇，分别为 anchor、contents 以及 people，其中列簇 anchor 下有两列，分别为 cnnsi.com 以及 my.look.ca，其他两个列簇都仅有一列。可以看出，根据行 com.cnn.www 以及列 anchor:nnsi.com 可以定位到数据 CNN，对应的时间戳信息是 t9。而同一行的另一列 contents:html 下却有三个版本的数据，版本号分别为 t5、t6 和 t7。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502181239810.png)

总体来看，HBase 的逻辑视图是比较容易理解的，需要注意的是，HBase 引入了列簇的概念，列簇下的列可以动态扩展；另外，HBase 使用时间戳实现了数据的多版本支持。

---

### 多维稀疏排序 Map

要真正理解 HBase 的工作原理，需要从 KV 数据库这个视角重新对其审视。BigTable 论文中称 BigTable 为"sparse，distributed，persistent multidimensionalsorted map"，可见 BigTable 本质上是一个 Map 结构数据库，HBase 亦然，也是由一系列 KV 构成的。然而 HBase 这个 Map 系统却并不简单，有很多限定词——稀疏的、分布式的、持久性的、多维的以及排序的。接下来，我们先对这个 Map 进行解析，这对于之后理解 HBase 的工作原理非常重要。

**HBase 中 Map 的 key 是一个复合键**，由 **rowkey、column family、qualifier、type 以及 timestamp** 组成，value 即为 cell 的值。举个例子，上节逻辑视图中行 `com.cnn.www` 以及列 `anchor：cnnsi.com` 对应的数值 `CNN` 实际上在 HBase 中存储为如下 KV 结构：

```
{"com.cnn.www","anchor","cnnsi.com","put","t9"} -> "CNN"
```

在此基础上再来介绍多维、稀疏、排序等关键词：

^^多维^^

: 这个特性比较容易理解。HBase 中的 Map 与普通 Map 最大的不同在于，key 是一个复合数据结构，由多维元素构成，包括 rowkey、column family、qualifier、type 以及 timestamp。

^^稀疏^^

: 稀疏性是 HBase 一个突出特点。从上图逻辑表中行 `com.example.www` 可以看出，整整一行仅有一列（people：author）有值，其他列都为空值。在其他数据库中，对于空值的处理一般都会填充 null，而对于 HBase，空值不需要任何填充。这个特性为什么重要？因为 HBase 的列在理论上是允许无限扩展的，对于成百万列的表来说，通常都会存在大量的空值，如果使用填充 null 的策略，势必会造成大量空间的浪费。因此稀疏性是 HBase 的列可以无限扩展的一个重要条件。

^^排序^^

: 构成 HBase 的 KV 在同一个文件中都是有序的，但规则并不是仅仅按照 rowkey 排序，而是按照 KV 中的 key 进行排序——先比较 rowkey，rowkey 小的排在前面；如果 rowkey 相同，再比较 column，即 column family：qualifier，column 小的排在前面；如果 column 还相同，再比较时间戳 timestamp，即版本信息，timestamp 大的排在前面。这样的多维元素排序规则对于提升 HBase 的读取性能至关重要。

^^分布式^^

: 很容易理解，构成 HBase 的所有 Map 并不集中在某台机器上，而是分布在整个集群中。

---

### 物理视图

与大多数数据库系统不同，HBase 中的数据是按照列簇存储的，即将数据按照列簇分别存储在不同的目录中。

列簇 anchor 的所有数据存储在一起形成：

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502181308985.png)

列簇 contents 的所有数据存储在一起形成：

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502181309031.png)

!!! question "为什么 HBase 要将数据按照列簇分别存储？"

**列簇式存储：**从概念上来说，列簇式存储介于行式存储和列式存储之间，可以通过不同的设计思路在行式存储和列式存储两者之间相互切换。比如，一张表只设置一个列簇，这个列簇包含所有用户的列。HBase 中一个列簇的数据是存储在一起的，因此这种设计模式就等同于行式存储。再比如，一张表设置大量列簇，每个列簇下仅有一列，很显然这种设计模式就等同于列式存储。上面两例当然是两种极端的情况，在当前体系中不建议设置太多列簇，但是这种架构为 HBase 将来演变成 HTAP（Hybrid Transactional and Analytical Processing）系统提供了最核心的基础。

---

## HBase 体系架构

HBase 体系结构借鉴了 BigTable 论文，是典型的 Master-Slave 模型。系统中有一个管理集群的 Master 节点以及大量实际服务用户读写的 RegionServer 节点。除此之外，HBase 中所有数据最终都存储在 HDFS 系统中，这与 BigTable 实际数据存储在 GFS 中相对应；系统中还有一个 ZooKeeper 节点，协助 Master 对集群进行管理。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202502181314664.png)

^^HBase 客户端^^

: HBase 客户端（Client）提供了 Shell 命令行接口、原生 Java API 编程接口、Thrift/REST API 编程接口以及 MapReduce 编程接口。HBase 客户端支持所有常见的 DML 操作以及 DDL 操作，即数据的增删改查和表的日常维护等。其中 Thrift/REST API 主要用于支持非 Java 的上层业务需求，MapReduce 接口主要用于批量数据导入以及批量数据读取。

: HBase 客户端访问数据行之前，首先需要通过元数据表定位目标数据所在 RegionServer，之后才会发送请求到该 RegionServer。同时这些元数据会被缓存在客户端本地，以方便之后的请求访问。如果集群 RegionServer 发生宕机或者执行了负载均衡等，从而导致数据分片发生迁移，客户端需要重新请求最新的元数据并缓存在本地。

^^Zookeeper^^

在 HBase 系统中，ZooKeeper 扮演着非常重要的角色：

- 实现 Master 高可用：通常情况下系统中只有一个 Master 工作，一旦 Active Master 由于异常宕机，ZooKeeper 会检测到该宕机事件，并通过一定机制选举出新的 Master，保证系统正常运转。
- 管理系统核心元数据：比如，管理当前系统中正常工作的 RegionServer 集合，保存系统元数据表 `hbase:meta` 所在的 RegionServer 地址等。
- 参与 RegionServer 宕机恢复：ZooKeeper 通过心跳可以感知到 RegionServer 是否宕机，并在宕机后通知 Master 进行宕机处理。
- 实现分布式表锁：HBase 中对一张表进行各种管理操作（比如 alter 操作）需要先加表锁，防止其他用户对同一张表进行管理操作，造成表状态不一致。和其他 RDBMS 表不同，HBase 中的表通常都是分布式存储，ZooKeeper 可以通过特定机制实现分布式表锁。

^^Master^^

Master 主要负责 HBase 系统的各种管理工作：

- 处理用户的各种管理请求，包括建表、修改表、权限操作、切分表、合并数据分片以及 Compaction 等。
- 管理集群中所有 RegionServer，包括 RegionServer 中 Region 的负载均衡、RegionServer 的宕机恢复以及 Region 的迁移等。
- 清理过期日志以及文件，Master 会每隔一段时间检查 HDFS 中 HLog 是否过期、HFile 是否已经被删除，并在过期之后将其删除。

^^RegionServer^^

RegionServer 主要用来响应用户的 IO 请求，是 HBase 中最核心的模块，由 WAL（HLog）、BlockCache 以及多个 Region 构成。

- WAL（HLog）：HLog 在 HBase 中有两个核心作用——其一，用于实现数据的高可靠性，HBase 数据随机写入时，并非直接写入 HFile 数据文件，而是先写入缓存，再异步刷新落盘。为了防止缓存数据丢失，数据写入缓存之前需要首先顺序写入 HLog，这样，即使缓存数据丢失，仍然可以通过 HLog 日志恢复；其二，用于实现 HBase 集群间主从复制，通过回放主集群推送过来的 HLog 日志实现主从复制。
- BlockCache：HBase 系统中的读缓存。客户端从磁盘读取数据之后通常会将数据缓存到系统内存中，后续访问同一行数据可以直接从内存中获取而不需要访问磁盘。对于带有大量热点读的业务请求来说，缓存机制会带来极大的性能提升。

!!! note "BlockCache"

    BlockCache 缓存对象是一系列 Block 块，一个 Block 默认为 64K，由物理上相邻的多个 KV 数据组成。BlockCache 同时利用了空间局部性和时间局部性原理，前者表示最近将读取的 KV 数据很可能与当前读取到的 KV 数据在地址上是邻近的，缓存单位是 Block（块）而不是单个 KV 就可以实现空间局部性；后者表示一个 KV 数据正在被访问，那么近期它还可能再次被访问。当前 BlockCache 主要有两种实现——LRUBlockCache 和 BucketCache，前者实现相对简单，而后者在 GC 优化方面有明显的提升。

- Region：数据表的一个分片，当数据表大小超过一定阈值就会“水平切分”，分裂为两个 Region。Region 是集群负载均衡的基本单位。通常一张表的 Region 会分布在整个集群的多台 RegionServer 上，一个 RegionServer 上会管理多个 Region，当然，这些 Region 一般来自不同的数据表。

!!! note "Region"

    一个 Region 由一个或者多个 Store 构成，Store 的个数取决于表中列簇（column family）的个数，多少个列簇就有多少个 Store。HBase 中，每个列簇的数据都集中存放在一起形成一个存储单元 Store，因此建议将具有相同 IO 特性的数据设置在同一个列簇中。
    每个 Store 由一个 MemStore 和一个或多个 HFile 组成。MemStore 称为写缓存，用户写入数据时首先会写到 MemStore，当 MemStore 写满之后（缓存数据超过阈值，默认 128M）系统会异步地将数据 flush 成一个 HFile 文件。显然，随着数据不断写入，HFile 文件会越来越多，当 HFile 文件数超过一定阈值之后系统将会执行 Compact 操作，将这些小文件通过一定策略合并成一个或多个大文件。

^^HDFS^^

HBase 底层依赖 HDFS 组件存储实际数据，包括用户数据文件、HLog 日志文件等最终都会写入 HDFS 落盘。HDFS 是 Hadoop 生态圈内最成熟的组件之一，数据默认三副本存储策略可以有效保证数据的高可靠性。HBase 内部封装了一个名为 DFSClient 的 HDFS 客户端组件，负责对 HDFS 的实际数据进行读写访问。

---

## HBase 系统优缺点

### 优点

与其他数据库相比，HBase 在系统设计以及实际实践中有很多独特的优点：

- **容量巨大**：HBase 的单表可以支持千亿行、百万列的数据规模，数据容量可以达到 TB 甚至 PB 级别。传统的关系型数据库，如 Oracle 和 MySQL 等，如果单表记录条数超过亿行，读写性能都会急剧下降，在 HBase 中并不会出现这样的问题。
- **良好的可扩展性**：HBase 集群可以非常方便地实现集群容量扩展，主要包括数据存储节点扩展以及读写服务节点扩展。HBase 底层数据存储依赖于 HDFS 系统，HDFS 可以通过简单地增加 DataNode 实现扩展，HBase 读写服务节点也一样，可以通过简单的增加 RegionServer 节点实现计算层的扩展。
- **稀疏性**：HBase 支持大量稀疏存储，即允许大量列值为空，并不占用任何存储空间。这与传统数据库不同，传统数据库对于空值的处理要占用一定的存储空间，这会造成一定程度的存储空间浪费。因此可以使用 HBase 存储多至上百万列的数据，即使表中存在大量的空值，也不需要任何额外空间。
- **高性能**：HBase 目前主要擅长于 OLTP 场景，数据写操作性能强劲，对于随机单点读以及小范围的扫描读，其性能也能够得到保证。对于大范围的扫描读可以使用 MapReduce 提供的 API，以便实现更高效的并行扫描。
- **多版本**：HBase 支持多版本特性，即一个 KV 可以同时保留多个版本，用户可以根据需要选择最新版本或者某个历史版本。
- **支持过期**：HBase 支持 TTL 过期特性，用户只需要设置过期时间，超过 TTL 的数据就会被自动清理，不需要用户写程序手动删除。
- **Hadoop 原生支持**：HBase 是 Hadoop 生态中的核心成员之一，很多生态组件都可以与其直接对接。HBase 数据存储依赖于 HDFS，这样的架构可以带来很多好处，比如用户可以直接绕过 HBase 系统操作 HDFS 文件，高效地完成数据扫描或者数据导入工作；再比如可以利用 HDFS 提供的多级存储特性（Archival Storage Feature），根据业务的重要程度将 HBase 进行分级存储，重要的业务放到 SSD，不重要的业务放到 HDD。或者用户可以设置归档时间，进而将最近的数据放在 SSD，将归档数据文件放在 HDD。另外，HBase 对 MapReduce 的支持也已经有了很多案例，后续还会针对 Spark 做更多的工作。

---

### 缺点

- HBase 本身不支持很复杂的聚合运算（如 Join、GroupBy 等）。如果业务中需要使用聚合运算，可以在 HBase 之上架设 Phoenix 组件或者 Spark 组件，前者主要应用于小规模聚合的 OLTP 场景，后者应用于大规模聚合的 OLAP 场景。
- HBase 本身并没有实现二级索引功能，所以不支持二级索引查找。好在针对 HBase 实现的第三方二级索引方案非常丰富，比如目前比较普遍的使用 Phoenix 提供的二级索引功能。
- HBase 原生不支持全局跨行事务，只支持单行事务模型。同样，可以使用 Phoenix 提供的全局事务模型组件来弥补 HBase 的这个缺陷。
