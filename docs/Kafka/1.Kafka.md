# Kafka

## 生产者与消费者模型

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202411210651967.png)

生产者消费者模式（Producer-Consumer Pattern）是经典的线程同步案例，也被称为有限缓冲问题。

^^生产者的职责:^^
: 生产者负责产生数据，但产生的数据量不能超出缓冲区的限制。当缓冲区已满时，生产者需要停止生产。

^^消费者的职责:^^
: 消费者负责消费生产者产生的数据。当缓冲区为空时，消费者需要停止消费。

^^缓冲区的数据结构:^^
: 上述的缓冲区可以通过多种数据结构来表示，例如数组、列表等。在存储形式上，缓冲区可以存在于内存或者磁盘中。

^^队列在生产者消费者模式中的应用:^^
: 根据实际业务需求，通常会使用队列这种数据结构来作为缓冲区。队列的优点是 FIFO 原则，即先进入队列的数据先被取出。由于实际需求往往是希望先生产的消息先被消费，所以这种队列通常又被称为消息队列。

---

## 消息队列

消息队列是一种在分布式计算环境中使用的技术，用于在不同的进程或服务之间传递消息。它通常被视为一种中间件，具有以下特点：

**消息队列的特点:**

- **队列结构**：消息队列可以看作是一个特殊的队列，其中的消息按照一定的顺序排列，确保 FIFO 的原则得到执行。
- **异步处理**：消息队列允许将消息放入队列后，无需等待立即处理，而是可以继续执行其他任务。随后，另一个程序会定期读取队列中的消息，并根据业务逻辑按顺序进行处理。
- **应用解耦**：通过使用消息队列，可以将不同服务的通信需求抽象化，从而降低它们之间的耦合度。
- **负载均衡**：在某些情况下，如分布式系统中，消息队列可以帮助平衡并发请求，防止过载。
- **可靠性保障**：消息队列通常会提供一定程度的可靠性和持久性，以确保消息不会丢失或在网络分区的情况下仍然能够保持状态。

---

## Kafka 简介

kafka 是一个分布式消息队列，具有高性能、持久化、多副本备份、横向扩展能力。

kafka 对外使用 topic 的概念，生产者往 topic 里写消息，消费者从 topic 里读消息。

为了做到水平扩展，一个 topic 实际是由多个 partition 组成的，遇到瓶颈时，可以通过增加 partition 的数量来进行横向扩容。

**Kafka 的特性：**

- 高吞吐量、低延迟：Kafka 每秒可以处理几十万条消息，它的延迟最低只有几毫秒
- 可扩展性：Kafka 集群支持热扩展
- 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- 容错性：允许集群中节点失败（若副本数量为 n，则允许 n-1 个节点失败）
- 高并发：支持数千个客户端同时读写

---

## Kafka 架构

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202411210712362.png)

---

## Kafka 术语解析

### Broker

Kafka 集群包含一个或多个服务器，其中服务器节点被称作 Broker，属于物理概念。

### Producer

Producer 是负责向 Kafka 服务端写入数据的程序。

### Topic

Topic 是一个逻辑概念，可将其视为一个消息类别的名称。同类消息会被发送到同一个 Topic 之下，例如订单消息，只会被发送到订单 Topic 中，也就是说 Kafka 是面向 Topic 的。从物理层面来讲，不同 Topic 对应的消息是分开存储的。Topic 就好比是数据库的表，尤其是在分库分表之后的那种逻辑表。

### Partition

Partition 属于物理概念，每个 Topic 包含一个或多个 Partition，所以 Partition 是最小的存储单元，存储着一个 Topic 的部分数据。每个 Partition 都是一个单独的 log 文件，每条记录均以追加的形式写入。当生产者产生数据时，会依据分配策略来选择分区，进而将消息追加到指定分区的末尾（类似队列操作），而消费者在消费的时候则是从头开始进行消费的。

---

为了做到均匀分布，通常 Partition 的数量通常是 Broker Server 数量的整数倍。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202411210717607.png)

生产经验告诉我们，虽然增加分区数可以提高 Kafka 集群的吞吐量，但过多的分区或单台服务器上的分区数过多，会增加不可用性和延迟的风险。这是因为：

- 更多的分区：意味着需要打开更多的文件句柄。
- 增加延迟：点到点的延迟会随之增加。
- 内存消耗：客户端的内存消耗也会增加。

---

### Replica

Replica 是 partition 的副本，保障 partition 的高可用性。Kafka 根据使用场景不同，通常会有以下一些关键名词：

- **AR (Assigned Replicas)**：分配给这个分区的副本集合，即一个分区的所有副本，包括 leader 和 follower。

- **ISR (In-sync Replicas)**：同步副本集，指与 leader 保持同步且同步时间差不大于参数 `replica.lag.time.max.ms`（默认值为 10 秒）的副本。如果 follower 长时间未向 leader 发送通信请求或同步数据，则该 follower 将被剔除出 ISR。如果 leader 发生故障，将从 ISR 中选举新的 leader。

- **OSR (Out of Sync Replicas)**：与 leader 副本同步时延迟过多的副本。

因此，可以得出结论： **AR = ISR + OSR**

- **CUR (Catch-up Replicas)**：追赶复制集，指正在与 leader 保持同步过程中的副本。

- **RAR (Reassigned Replicas)**：重新分配副本集，和 leader 保持同步。

副本集中主要有两个角色：

1. **Leader**：replica 中的一个角色，producer 和 consumer 只与 leader 交互。
2. **Follower**：replica 中的一个角色，从 leader 中复制数据。

**总结**：每个 partition 有多个副本，其中有且仅有一个作为 leader，leader 是当前负责数据的**读写**的 partition。

---

### Consumer Group

每个 Consumer 都属于一个 Consumer Group，这是一个逻辑概念。来自同一个 topic 的数据可以由不同的 consumer group 中的 consumer 进行消费；**但同一个 group 中的不同 consumer 只能消费不同的 partition**。

Group 内的 consumer 可以使用多线程或多进程来实现，也可以将进程分散在多台机器上。通常，consumer 的数量不超过 partition 的数量，且二者最好保持整数倍关系。这是因为 Kafka 在设计时假定一个 partition 只能被同一个 group 内的一个 consumer 消费。

如果 consumer group 中的 consumer 线程数量少于 partition 数量，那么有的线程将会收到多个消息。由于 Kafka 只能保证在一个 partition 上数据是有序的，因此，如果一个 consumer 消费一个 topic 的多个分区，就可能出现数据乱序的情况。

!!! note "总结"

    1. Consumer Group 下可以有一个或多个 consumer 实例，consumer 实例可以是一个进程，也可以是一个线程。
    2. group.id 是一个字符串，唯一标识一个 consumer group。
    3. Consumer Group 下订阅的 topic 中的每个分区只能分配给某个 group 下的一个 consumer（当然，该分区还可以被分配给其他 group）。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202411210738692.png)

---

### Offset

消费者在消费过程中需要记录自己消费了多少数据，即消费位置信息。在 Kafka 中，这个位置信息有一个专门的术语：**位移 (offset)**。Offset 表明了某个 Consumer Group 在不同 Topic Partition 上的消费偏移量（也可以理解为消费进度），它记录了 Consumer 要消费的下一条消息的位移。

Consumer 需要向 Kafka 上报自己的位移数据信息，我们将这个上报过程称为 **提交位移 (Committing Offsets)**。提交位移是为了保证 Consumer 的消费进度正常。当 Consumer 发生故障重启后，可以直接从之前提交的 Offset 位置开始继续消费，而不需要重新开始（Kafka 认为小于提交的 Offset 的消息都已经成功消费了）。Kafka 设计了这个机制来保障消费进度。

我们知道，Consumer 可以同时去消费多个分区的数据，所以位移提交是按照分区的粒度进行上报的。这意味着 Consumer 需要为分配给它的每个分区提交各自的位移数据。

---

很多消息引擎都将这部分信息保存在服务器端（broker 端）。这样做的好处当然是实现简单，但会面临三个主要问题：

1. **Broker 从此变成有状态的**：这会影响系统的伸缩性。
2. **需要引入应答机制 (acknowledgement)**：来确认消费成功。
3. **保存大量 Consumer 的 Offset 信息**：必然引入复杂的数据结构，造成资源浪费。

而 Kafka 选择了不同的方式：每个 Consumer Group 保存自己的位移信息，这样只需要简单的一个整数表示位置即可。同时，Kafka 可以引入检查点机制定期持久化，从而简化应答机制的实现。Consumer Group 中的所有 Consumer 使用一套 Offset。

Kafka 默认是定期自动提交位移（`auto.commit.interval.ms=5000ms`，`enable.auto.commit = true`）。当然，用户也可以选择手动提交位移以实现更细致的控制。

另外，Kafka 会定期将 Consumer Group 的消费情况保存起来，形成一个 Offset Map，如下图所示：

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202411210742238.png)

Kafka 老版本（0.8.0）的位移是提交到 Zookeeper 中的，对应的目录结构是：
`/consumers/<group.id>/offsets/<topic>/<partitionId>`

但是，Zookeeper 其实并不适合进行大批量的读写操作，尤其是写操作。因此，Kafka 提供了另一种解决方案：增加了内部的 topic `__consumer_offsets`，将 offset 信息写入这个 topic，摆脱了对 Zookeeper 的依赖（指保存 offset 这件事情）。`__consumer_offsets` 中的消息保存了每个 consumer group 在某一时刻提交的 offset 信息。

---

在 Kafka 中，关于位置信息有很多 ，如下图所示：

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202411210744691.png)

对生产者而言：

- **Log End Offset (LEO)**：记录底层日志 (log) 中下一条消息的 offset。对 producer 来说，这就是即将插入下一条消息的 offset。

- **High Watermark (HW)**：已经成功备份到其他 replicas 中的最新一条数据的 offset。也就是说，Log End Offset 与 High Watermark 之间的数据已经写入到该 partition 的 leader 中，但还未完全备份到其他 replicas 中，consumer 是无法消费这部分消息（未提交消息）。由于网络问题，有些 follower 可能同步得比较慢，因此 HW 就是所有 follower 中同步最小的 LEO。

![](https://raw.githubusercontent.com/LIMUXUALE0927/image/main/img/202411210746068.png)

对消费者而言：

- **Last Committed Offset (LCO)**：consumer group 最新一次 commit 的 offset，表示这个 group 已经成功消费了 Last Committed Offset 之前的数据。

- **Current Position (CP)**：consumer group 当前消费数据的 offset，也就是说，Last Committed Offset 到 Current Position 之间的数据已经拉取成功，可能正在处理，但尚未 commit。

其中，**HW - CP = Lag**，计算出来的值即为消费延迟情况。

每个 Kafka 副本对象都有两个重要的属性：**LEO** 和 **HW**。注意，这适用于所有的副本，而不仅仅是 leader 副本。

此外，关于 consumer，这里涉及到两个 offset：

- **Current Position**：当前消费数据的 offset。
- **Last Committed Offset**：处理完毕后向服务器确认的 offset。

显然，在异步模式下，Last Committed Offset 是落后于 Current Position 的。如果 consumer 挂掉了，下次消费数据时只会从 Last Committed Offset 的位置拉取数据，这将导致数据被重复消费。

可以通过参数 `auto.offset.reset` 指定 Offset 消费，主要有以下几个取值：

- **earliest**：当各分区下有已提交的 offset 时，从最近一次提交的 offset 开始消费；无提交的 offset 时，从头开始消费。

- **latest**：当各分区下有已提交的 offset 时，从最近一次提交的 offset 开始消费；无提交的 offset 时，消费新产生的该分区下的数据（默认值）。

- **none**：当各分区都存在已提交的 offset 时，从最近一次提交的 offset 后开始消费；只要有一个分区不存在已提交的 offset，则抛出异常。

```scala
public enum OffsetResetStrategy {
    LATEST , EARLIEST , NONE
}
```

---

**工作场景一**：Kafka 上实时被灌入数据，但 Kafka 上已经积累了两天的数据，如何从最新的 offset 开始消费？（最新指相对于当前系统时间的最新）

**回答**：将 `group.id` 换成新的名字（相当于加入新的消费组）。

**备注**：网上文章提到还需要设置 `properties.setProperty("auto.offset.reset", "latest")`。实验发现，即使不设置这个，因为默认值就是 `latest`，只要 `group.id` 是全新的，就会从最新的 offset 开始消费。

---

**工作场景二**：Kafka 在实时灌入数据，Kafka 上已经积累了两天的数据，如何从两天前最开始的位置消费？

1. 将 `group.id` 换成新的名字。
2. 设置 `properties.setProperty("auto.offset.reset", "earliest")`。

---

**工作场景三**：不更改 `group.id`，只是添加了 `properties.setProperty("auto.offset.reset", "earliest")`，consumer 会从两天前最开始的位置消费吗？

**回答**：不会。只要不更改消费组，只会从上次消费结束的地方继续消费。

---

**工作场景四**：不更改 `group.id`，只是添加了 `properties.setProperty("auto.offset.reset", "latest")`，consumer 会从距离现在最近的位置消费吗？

**回答**：不会，只要不更改消费组，consumer 只会从上次消费结束的地方继续消费。
